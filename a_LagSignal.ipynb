{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne                                                              # Librería de python para explorar, visualizar,\n",
    "mne.set_log_level('WARNING')                                            # y analizar datos neurofisiológicos humanos.\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb                                                    \n",
    "color = ['green', 'blue','red','cyan', 'magenta', 'yellow','k','w']     # Paleta de colores para diferenciar las ondas\n",
    "\n",
    "import a_funciones as a_fun                                             # Funciones Alex\n",
    "\n",
    "xlabel = 'Muestra'                                                      # Abscisas\n",
    "ylabel = 'Amplitud (uV)'                                                # Ordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Mismatch between array dtype ('object') and format specifier ('%.18e')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\alexc\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[0;32m   1432\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1433\u001b[1;33m                     \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1434\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5900/2860399422.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mmeta_P300S01\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msignal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./a_results/meta_P300S01.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta_P300S01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcont_P300S01\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeta_P300S01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msavetxt\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alexc\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[0;32m   1433\u001b[0m                     \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1434\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1435\u001b[1;33m                     raise TypeError(\"Mismatch between array dtype ('%s') and \"\n\u001b[0m\u001b[0;32m   1436\u001b[0m                                     \u001b[1;34m\"format specifier ('%s')\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1437\u001b[0m                                     % (str(X.dtype), format)) from e\n",
      "\u001b[1;31mTypeError\u001b[0m: Mismatch between array dtype ('object') and format specifier ('%.18e')"
     ]
    }
   ],
   "source": [
    "mat = scipy.io.loadmat('./dataset/ERPTemplate.mat')\n",
    "routput = mat['routput']\n",
    "erptemplate1 = routput[0][7][0][1][0][0][0][7] \n",
    "erptemplate1 = np.delete( erptemplate1, range(0,256,43),0)\n",
    "\n",
    "punto_mat = scipy.io.loadmat('./dataset/itba/P300S01.mat') # P300S01 Pertenece al grupo pasivo. No tiene ERP.\n",
    "signal = punto_mat['data'][0][0][0] \n",
    "#t_trials = punto_mat['data'][0][0][3]\n",
    "t_flash = punto_mat['data'][0][0][4]\n",
    "#t_stim = mat['data'][0][0][2]\n",
    "#t_type = mat['data'][0][0][1]\n",
    "\n",
    "lag_flash = [1,10,50,100,-100]\n",
    "meta_P300S01 = np.empty(len(lag_flash), dtype=object)\n",
    "for j,lag in enumerate(lag_flash):   \n",
    "    #print(f'j:{j} | Contenido de j:{lag}')\n",
    "    signal = punto_mat['data'][0][0][0] \n",
    "    for i in range(0,4200):\n",
    "        if (t_flash[i,3]==2):\n",
    "            signal[t_flash[i,0]-lag:t_flash[i,0]+250-lag,:] += (erptemplate1*3)\n",
    "    meta_P300S01[j] = signal\n",
    "\n",
    "np.savetxt('./a_results/meta_P300S01.csv', meta_P300S01, delimiter=',')\n",
    "\n",
    "for j, cont_P300S01 in enumerate(meta_P300S01):   \n",
    "    #print(f'j:{j} | Contenido de j:{cont_P300S01}')\n",
    "    df = a_fun.to_df(cont_P300S01)\n",
    "    plt.figure(figsize=(30,8))                           \n",
    "    axes = plt.gca()\n",
    "    for i in range(0,7):\n",
    "        plt.plot(df['sample'], df[i], color[i])\n",
    "    axes.set_title(f'P300S01 con un desfase de {lag_flash[j]} '), axes.title.set_size(30)\n",
    "    axes.set_xlabel(xlabel), axes.set_ylabel(ylabel)\n",
    "    axes.xaxis.label.set_size(20), axes.yaxis.label.set_size(20)\n",
    "    plt.xlim([228000,229000]) \n",
    "    plt.ylim([-180,180])\n",
    "    #plt.savefig(\"./a_images/DrguSignal2_zoom.jpg\")\n",
    "    plt.grid(), plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#-------------------------------------\n",
    "def DrugSignal(signal, t_flash):\n",
    "    for i in range(0,4200):\n",
    "        if (t_flash[i,3]==2):\n",
    "            signal[t_flash[i,0]-1:t_flash[i,0]+250-1,:] += (erptemplate1*3)\n",
    "    return signal\n",
    "#-------------------------------------\n",
    "'''\n",
    "mult_erp = np.array([1, 50, 100]) #, 200, 400]) # mult_erp: Vector que contiene los multiplicadores para ampliar el ERP. \n",
    "vector_signal = np.array()\n",
    "# Por a hora DrugSignal2 NO está funcionando.\n",
    "def DrugSignal2(signal, t_flash, mult_erp):\n",
    "    for i in range(0,mult_erp.size):\n",
    "        for j in range(0,4200):\n",
    "            if (t_flash[j,3]==2):\n",
    "                signal[t_flash[j,0]-1:t_flash[j,0]+250-1,:] += (erptemplate1*mult_erp[i])\n",
    "        vector_signal[i]=signal                \n",
    "    return vector_signal\n",
    "'''\n",
    "#-------------------------------------\n",
    "# Pacientes para el experimento PASIVO: P300S01,02,03,06. | Pacientes para el experimento ACTIVO: P300S04, 05, 07 y 08.\n",
    "# files_path_itba_test = ['./dataset/itba/P300S01.mat', './dataset/itba/P300S02.mat']\n",
    "files_path_itba_test = ['./dataset/itba/P300S01.mat', './dataset/itba/P300S02.mat', './dataset/itba/P300S03.mat', './dataset/itba/P300S04.mat', \n",
    "                    './dataset/itba/P300S05.mat', './dataset/itba/P300S06.mat', './dataset/itba/P300S07.mat', './dataset/itba/P300S08.mat']\n",
    "'''\n",
    "files_path_itba = ['./dataset/itba/P300S01.mat', \n",
    "                    './dataset/itba/P300S02.mat',\n",
    "                    './dataset/itba/P300S03.mat', \n",
    "                    #'./dataset/itba/P300S04.mat', \n",
    "                    # './dataset/itba/P300S05.mat',\n",
    "                    './dataset/itba/P300S06.mat']\n",
    "                    #, \n",
    "                    # './dataset/itba/P300S07.mat', \n",
    "                    # './dataset/itba/P300S08.mat']\n",
    "'''\n",
    "files_path_bnci = ['./dataset/bnci/A01.mat', './dataset/bnci/A02.mat', './dataset/bnci/A03.mat', './dataset/bnci/A04.mat',\n",
    "              './dataset/bnci/A05.mat', './dataset/bnci/A06.mat', './dataset/bnci/A07.mat', './dataset/bnci/A08.mat']\n",
    "#-------------------------------------\n",
    "for ii, path in enumerate(files_path_itba_test):   \n",
    "    results_mne=f'./a_results/Paciente P300S0{ii+1}.csv' # Si necesitás, con cambiar la extensión a.txt es suficiente\n",
    "    file_temp=open(results_mne,\"w\") \n",
    "    print(f'Paciente P300S0{ii+1},', file=file_temp) # COLUMNA0.\n",
    "    punto_mat=scipy.io.loadmat(path)\n",
    "    signal = punto_mat['data'][0][0][0] \n",
    "    t_trials = punto_mat['data'][0][0][3]\n",
    "    t_flash = punto_mat['data'][0][0][4]\n",
    "#-------------------------------------\n",
    "# NOTA IMPORTANTE: SI DROGÁS LA SEÑAL ES PORQUE ESTÁS USANDO UNA TRAZA EEG DE PACIENTES EN MODALIDAD PASIVA.\n",
    "# Es decir, que no se están enfocando en nada particular. Con éstos EEG + ERP se crea el dataset sintético.\n",
    "#-------------------------------------\n",
    "#    signal = DrugSignal(signal, t_flash)\n",
    "#-------------------------------------\n",
    "    t_stim = punto_mat['data'][0][0][2]\n",
    "    t_type = punto_mat['data'][0][0][1]\n",
    "    #-------------------------------------\n",
    "    ch_names=[ 'Fz'  ,  'Cz',    'P3' ,   'Pz'  ,  'P4'  ,  'PO7'   , 'PO8'   , 'Oz']\n",
    "    ch_types= ['eeg'] * signal.shape[1]\n",
    "    ch_names_events = ch_names + ['t_stim']+ ['t_type']\n",
    "    ch_types_events = ch_types + ['misc'] + ['misc']\n",
    "    #-------------------------------------\n",
    "    #info = mne.create_info(ch_names, 250, ch_types=ch_types)\n",
    "    #eeg_mne = mne.io.array.RawArray(signal.T, info)\n",
    "    signal_events = np.concatenate([signal, t_stim, t_type],1)\n",
    "    info_events = mne.create_info(ch_names_events,250, ch_types_events)\n",
    "    eeg = mne.io.RawArray(signal_events.T, info_events)\n",
    "    #-------------------------------------\n",
    "    #fig=eeg.plot_psd()\n",
    "    eeg.filter(1,20)\n",
    "    #fig=eeg.plot_psd()\n",
    "    event_times = mne.find_events(eeg, stim_channel='t_type') \n",
    "    print(f'Eventos coincidentes encontrados (sin tmin & tmax), {event_times[:,0].size}', file=file_temp) # También se puede obtener con {len(event_times)}\n",
    "    print(f'IDs de los eventos, {np.max(event_times[:,2])}', file=file_temp)\n",
    "    #eeg.plot(scalings='auto',n_channels=8,events=event_times,block=True)   # scalings=10e-05\n",
    "    #-------------------------------------\n",
    "    if (np.unique(t_flash[:,0]).shape[0] != 4200):                          # evalúa si el \"sample point id\" de t_flash tiene el tamaño correcto.\n",
    "        u,c = np.unique( t_flash[:,0], return_counts=True)                  # u->Los elementos únicos. c->la cantidad de veces que se repiten.\n",
    "        dup = u[c>1]                                                        # dup->Los que estén repetidos mas de una vez.    \n",
    "        \n",
    "        for i in range(dup.shape[0]):\n",
    "            idx = np.where( t_flash[:,0] == dup[i] )[0][0]\n",
    "            t_flash[idx,0]  -= 1\n",
    "            t_flash[idx,1]  = 1\n",
    "            t_type[t_flash[idx,0]] = t_flash[idx,3]\n",
    "            t_stim[t_flash[idx,0]] = t_flash[idx,2]\n",
    "\n",
    "    np.unique(t_flash[:,0]).shape\n",
    "    assert  np.unique(t_flash[:,0]).shape[0] == 4200, 'Problem with experiment structure.  There aren''t enough events.'\n",
    "    #-------------------------------------    \n",
    "    def getstims(eeg_mne, eeg_events):\n",
    "        '''\n",
    "        Get the stimulations.  These are the FLASHINGS of rows and columns.\n",
    "        '''\n",
    "        tmin = 0\n",
    "        tmax = 0.8\n",
    "        reject = None\n",
    "        event_times = mne.find_events(eeg_events, stim_channel='t_stim',shortest_event=0, verbose=True, min_duration=0.000001, consecutive=True)\n",
    "        #np.savetxt(file_temp, event_times, fmt='%d')\n",
    "        print(f'Eventos coincidentes encontrados (con tmin:0 & tmax:0.8), {event_times[:,0].size}', file=file_temp) # También se puede obtener con {len(event_times)}\n",
    "        print(f'IDs de los eventos, {np.max(event_times[:,2])}', file=file_temp)\n",
    "                        \n",
    "        event_id = {'Row1':1,'Row2':2,'Row3':3,'Row4':4,'Row5':5,'Row6':6,'Col1':7,'Col2':8,'Col3':9,'Col4':10,'Col5':11,'Col6':12}\n",
    "\n",
    "        epochs = mne.Epochs(eeg_mne, event_times, event_id, tmin, tmax, proj=False,\n",
    "                        baseline=None, reject=reject, preload=True,\n",
    "                        verbose=True, reject_by_annotation=None)\n",
    "        \n",
    "        stims = event_times[:,-1]\n",
    "        \n",
    "        #df_event_times = a_fun.to_df(event_times)    \n",
    "        #df_event_times.to_csv(f'./a_results/event_times_P300S0{ii+1}.csv', index=False)\n",
    "        return [epochs,stims]\n",
    "    #-------------------------------------    \n",
    "    stimepochs, stims = getstims(eeg, eeg)\n",
    "    #-------------------------------------    \n",
    "    '''\n",
    "    print('1///--------------------------------------')\n",
    "    print(f'{event_times[:,0].size} matching events found | {np.max(event_times[:,2])} Event IDs', file=file_temp)\n",
    "    print(f'stimepochs: {stimepochs} | stims: {stims}', file=file_temp)\n",
    "    #-------------------------------------\n",
    "    # HAY MAS INFO PERO POR AHORA NO LO GUARDAMOS EN EL ARCHIVO: print(f'getstims -> stimepochs, {stimepochs}', file=file_temp)\n",
    "    #-------------------------------------\n",
    "    print('---------------')\n",
    "    print(f'stims: \\n {stims}', file=file_temp)\n",
    "    #-------------------------------------\n",
    "    # HAY MAS INFO PERO POR AHORA NO LO GUARDAMOS EN EL ARCHIVO: print(f'getstims -> stims, {stims}', file=file_temp)\n",
    "    #-------------------------------------\n",
    "    print(stimepochs, stims)\n",
    "    print('2///--------------------------------------')\n",
    "    print('--------------------------------------Stimepochs:')\n",
    "    print(stimepochs)\n",
    "    print('Stims:', file=file_temp)\n",
    "    print(stims)\n",
    "    print(f'--------------- FIN Función: getstims --------------- \\n ', file=file_temp)\n",
    "    df_getstims_epochs = a_fun.to_df(epochs)\n",
    "    df_getstims_epochs.to_csv(f'./dataset/itba/getstims_epochs_P300S0{ii+1}.csv', index=False)\n",
    "    df_getstims = a_fun.to_df(stims)\n",
    "    df_getstims.to_csv(f'./dataset/itba/getstims_P300S0{ii+1}.csv', index=False)\n",
    "    '''\n",
    "    #-------------------------------------    \n",
    "    def getlabels(eeg_mne, eeg_events, event_id):\n",
    "        print(f'Etiqueta hit/no hit. flash de fil/col seleccionados \\n si son los que van a desencadenar la respuesta P300 o no.\\n-----------------------------------')\n",
    "        '''\n",
    "        Get the hit/no hits labels.  These are the FLASHINGS of rows and columns but selected if they are the ones that will\n",
    "        trigger the P300 response or not.\n",
    "        '''\n",
    "        #event_id = { 'first':1, 'second':2 }\n",
    "        #baseline = (0.0, 0.2)\n",
    "        #reject = {'eeg': 70 * pow(10,6)}\n",
    "        tmin = 0\n",
    "        tmax = 0.8\n",
    "        reject = None\n",
    "        event_times = mne.find_events(eeg_events, stim_channel='t_type', shortest_event=0, verbose=True, min_duration=0.000001, consecutive=True)\n",
    "        #print(f'{event_times[:,0].size} matching events found | {np.max(event_times[:,2])} Event IDs', file=file_temp)\n",
    "        #print(f'Eventos coincidentes encontrados, {event_times[:,0].size}', file=file_temp)\n",
    "        #print(f'IDs de los eventos, {np.max(event_times[:,2])}', file=file_temp)\n",
    "        epochs = mne.Epochs(eeg_mne, event_times, event_id, tmin, tmax, proj=False,\n",
    "                        baseline=None, reject=reject, preload=True,\n",
    "                        verbose=True, reject_by_annotation=None)\n",
    "        labels = epochs.events[:, -1]\n",
    "        return [epochs, labels]\n",
    "    #-------------------------------------    \n",
    "    epochs, labels = getlabels(eeg, eeg, {'first':1}) # -> {'first':1}: Nohits.\n",
    "    # Tupla de tres valores: epochs.get_data().shape . Tomo uno por uno\n",
    "    print(f'getlabels Nohits {ii+1} -> epochs, {(epochs.get_data().shape)[0]}', file=file_temp)\n",
    "    print(f'getlabels Nohits {ii+1} -> Channels, {(epochs.get_data().shape)[1]}', file=file_temp)\n",
    "    print(f'getlabels Nohits {ii+1} -> Time, {(epochs.get_data().shape)[2]}', file=file_temp)\n",
    "    print(f'getlabels Nohits {ii+1} -> labels (longitud), {len(labels)}', file=file_temp)\n",
    "    # epocked: Objeto de tipo <class 'mne.evoked.EvokedArray'>. \n",
    "    # En epocked.data puedo sacar info pero por ahora no hay nada. \n",
    "    # El profesor lo usa para visualizar: evoked.plot(). De acá se pueden sacar segmentos promedio.\n",
    "    epocked = epochs.average()\n",
    "    #-------------------------------------  \n",
    "    epochs, labels = getlabels(eeg, eeg, {'second':2}) # -> {'second':2}: Hits.\n",
    "    print(f'getlabels Hits {ii+1} -> epochs, {(epochs.get_data().shape)[0]}', file=file_temp)\n",
    "    print(f'getlabels Hits {ii+1} -> Channels, {(epochs.get_data().shape)[1]}', file=file_temp)\n",
    "    print(f'getlabels Hits {ii+1} -> Time, {(epochs.get_data().shape)[2]}', file=file_temp)\n",
    "    print(f'getlabels Hits {ii+1} -> labels (longitud), {len(labels)}', file=file_temp)\n",
    "    epocked = epochs.average()\n",
    "    #-------------------------------------    \n",
    "    '''\n",
    "    print(f'Esto es para el preprocesamiento de los modelos:', file=file_temp)\n",
    "    epochs, labels = getlabels(eeg, eeg, { 'first':1, 'second':2})\n",
    "    print(f'call#3_getlabels{ii+1} -> epochs, {epochs}', file=file_temp)\n",
    "    print(f'call#3_getlabels{ii+1} -> labels, {labels}', file=file_temp)\n",
    "    #print(f'Epochs:{epochs}', file=file_temp)\n",
    "    #print(f'Labels:{labels}', file=file_temp)\n",
    "    # Downsample the original FS=250 Hz signal to >>> 20 Hz\n",
    "    #epochs.resample(20, npad=\"auto\")\n",
    "    #stimepochs.resample(20, npad=\"auto\")\n",
    "    #print(f'--------------- FIN Función: getlabels --------------- \\n ', file=file_temp)\n",
    "    repetitions=120\n",
    "    '''\n",
    "    #-------------------------------------\n",
    "    #df_signal = pd.DataFrame(punto_mat['data'][0][0][0])  \n",
    "    #df_t_trials = pd.DataFrame(punto_mat['data'][0][0][3]) \n",
    "    #df_ t_flash = pd.DataFrame(mat['data'][0][0][4])\n",
    "    #df_t_stim = pd.DataFrame(mat['data'][0][0][2])\n",
    "    #df_t_type = pd.DataFrame(mat['data'][0][0][1])\n",
    "    #-------------------------------------\n",
    "    '''\n",
    "    #print(f'-------------------------------------- \\n TRANSFORMACIÓN A DATA FRAMES, por ahora no. \\n--------------------------------------', file=file_temp)\n",
    "    print(f'-----------eeg_crudo, Paciente P300S0{ii+1} -----------------', file=file_temp)\n",
    "    eeg_crudo=eeg.get_data()\n",
    "    eeg_crudo=eeg_crudo.T\n",
    "    primeras_filas_eeg_crudo = eeg_crudo[:5]\n",
    "    print(primeras_filas_eeg_crudo)\n",
    "    print(f'-----------type(eeg_crudo),Paciente P300S0{ii+1} ------------', file=file_temp)\n",
    "    print(type(eeg_crudo))\n",
    "    print(f'-----------types: df_alex & df_eeg,Paciente P300S0{ii+1} ----', file=file_temp)\n",
    "    df_alex = pd.DataFrame(eeg_crudo)       #<RawArray | 10 x 358372 (1433.\n",
    "    df_eeg = a_fun.to_df(eeg_crudo)\n",
    "    print(type(df_alex),file=file_temp)\n",
    "    print(type(df_eeg),file=file_temp)\n",
    "    print(df_eeg.columns,file=file_temp)\n",
    "    print(f'-----------df_alex, Paciente P300S0{ii+1} --------------------', file=file_temp)\n",
    "    print(df_alex.head(5),file=file_temp)\n",
    "    print(f'-----------df_eeg, Paciente P300S0{ii+1} --------------------', file=file_temp)\n",
    "    print(df_eeg.head(5), file=file_temp)\n",
    "    print('------------------------------------------------------------------------------------------------------------------', file=file_temp)\n",
    "\n",
    "    print(' \\n \\n \\n \\n BLA BLA BLA--------------------------------------------------------------------------------------------------- \\n \\n', file=file_temp)\n",
    "    print(f'{type(df_alex)} \\n {type(df_eeg)} \\n {df_eeg.columns} \\n -----------df_alex, Paciente P300S0{ii+1} -------------------- \\n {df_alex.head(5)}, \\n ----------------------------------- \\n {df_eeg.head(5)} \\n ------------------------------------------------------------------------------------------------------------------', file=file_temp)\n",
    "    \n",
    "    #-------------------------------------\n",
    "    ch_names_alex=['Fz','Cz','P3' ,'Pz','P4','PO7','PO8','Oz','sample']\n",
    "    ch_names_alex_events=['Fz','Cz','P3' ,'Pz','P4','PO7','PO8','Oz','t_stim','t_type','sample'] \n",
    "    #-------------------------------------\n",
    "    df_eeg.columns = ch_names_alex_events\n",
    "    df_eeg.to_csv(f'./a_results/df_eeg_P300S0{ii+1}.csv', index=False)\n",
    "    #-------------------------------------\n",
    "    df_signal = a_fun.to_df(signal)\n",
    "    ch_names_alex=['Fz','Cz','P3' ,'Pz','P4','PO7','PO8','Oz','sample']\n",
    "    df_signal.columns = ch_names_alex\n",
    "    df_signal.to_csv(f'./a_results/signals_P300S0{ii+1}.csv', index=False)       #df_t_trials.to_csv(f'./dataset/itba/Trials__P300S0{i+1}.csv', index=False)\n",
    "    #-------------------------------------\n",
    "    df_signal_events = a_fun.to_df(signal_events)    \n",
    "    df_signal_events.columns = ch_names_alex_events\n",
    "    df_signal_events.to_csv(f'./a_results/signal_events_P300S0{ii+1}.csv', index=False)\n",
    "    '''\n",
    "    #-------------------------------------\n",
    "    file_temp.close()\n",
    "    #-------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #punto_mat=scipy.io.loadmat(path)\n",
    "    #signal = punto_mat['data'][0][0][0] \n",
    "    #t_trials = punto_mat['data'][0][0][3]\n",
    "    #t_flash = punto_mat['data'][0][0][4]\n",
    "    #print(f'ESTOY TESTEANDO EL DRUGSIGNAL{ii+1}')\n",
    "    #signal = DrugSignal(signal, t_flash)\n",
    "    #t_stim = punto_mat['data'][0][0][2]\n",
    "    #t_type = punto_mat['data'][0][0][1]\n",
    "    #-------------------------------------\n",
    "    #ch_names=[ 'Fz'  ,  'Cz',    'P3' ,   'Pz'  ,  'P4'  ,  'PO7'   , 'PO8'   , 'Oz']\n",
    "    #ch_types= ['eeg'] * signal.shape[1]\n",
    "    #ch_names_events = ch_names + ['t_stim']+ ['t_type']\n",
    "    #ch_types_events = ch_types + ['misc'] + ['misc']\n",
    "    #-------------------------------------\n",
    "    #info = mne.create_info(ch_names, 250, ch_types=ch_types)\n",
    "    #eeg_mne = mne.io.array.RawArray(signal.T, info)\n",
    "    #signal_events = np.concatenate([signal, t_stim, t_type],1)\n",
    "    #print('-----------------info_events---------------------')\n",
    "    #info_events = mne.create_info(ch_names_events,250, ch_types_events)\n",
    "    #print(info_events)\n",
    "    #print('-----------------eeg---------------------')\n",
    "    #eeg = mne.io.RawArray(signal_events.T, info_events)\n",
    "    #print(eeg)\n",
    "    #print('-----------------eeg_crudo-----------------')\n",
    "    #eeg_crudo=eeg.get_data()\n",
    "    #df_alex = pd.DataFrame(eeg_crudo)\n",
    "    #<RawArray | 10 x 358372 (1433.\n",
    "    #df_eeg = a_fun.to_df(eeg_crudo)\n",
    "    \n",
    "df_eeg = a_fun.to_df(eeg_crudo)\n",
    "signal_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import mne\n",
    "#mne.set_log_level('WARNING')\n",
    "#import scipy.io\n",
    "#import numpy as np\n",
    "\n",
    "# First load the template.  This is the signal that will be used to DRUG the basal EEG stream.\n",
    "mat = scipy.io.loadmat('./dataset/ERPTemplate.mat')\n",
    "\n",
    "routput = mat['routput']\n",
    "\n",
    "# In this ERPTemplate, there are two different template signals that are good.\n",
    "erptemplate1 = routput[0][7][0][1][0][0][0][7] \n",
    "erptemplate2 = routput[0][7][0][1][0][0][0][0] \n",
    "\n",
    "# The original ERPTemplate dataset has a sampling frequency of 256 so I need to perform a small downsampling to 250 Hz\n",
    "erptemplate1 = np.delete( erptemplate1, range(0,256,43),0)\n",
    "erptemplate2 = np.delete( erptemplate2, range(0,256,43),0)\n",
    "\n",
    "# Use this for testing  (get a ZERO signal)\n",
    "#erptemplate1 = np.zeros((250,8))\n",
    "\n",
    "# Randomize amplitude and jitter.\n",
    "# Find the right locations where this should be inserted in the stream.\n",
    "# Insert the signal mantaining the continiuity of the EEG.\n",
    "def DrugSignal(signal, t_flash):\n",
    "    '''\n",
    "    Randomize amplitude and jitter\n",
    "    Find the right locations where this should be inserted in the stream\n",
    "    Insert the template mantaining the continuity and physiological meaning of the EEG\n",
    "    '''\n",
    "    for i in range(0,4200):\n",
    "        if (t_flash[i,3]==2):\n",
    "            signal[t_flash[i,0]-1:t_flash[i,0]+250-1,:] += (erptemplate1*3)\n",
    "\n",
    "    return signal\n",
    "\n",
    "#========================================================================================\n",
    "#========================================================================================\n",
    "#========================================================================================\n",
    "#========================================================================================\n",
    "#.\n",
    "#.\n",
    "#.\n",
    "#========================================================================================\n",
    "#========================================================================================\n",
    "#========================================================================================\n",
    "#========================================================================================\n",
    "\n",
    "# Now load the basal EEG stream\n",
    "#mat = scipy.io.loadmat('./dataset/p300-subject-25.mat')\n",
    "mat = scipy.io.loadmat('./dataset/itba/P300S01.mat')\n",
    "#mat = scipy.io.loadmat('./dataset/p300-subject-26.mat')\n",
    "#mat = scipy.io.loadmat('/Users/rramele/./GoogleDrive/Data/P300/p300-subject-21.mat')\n",
    "#mat = scipy.io.loadmat('/Users/rramele/./GoogleDrive/Data/P300/p300-subject-06.mat')\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "# coding: latin-1\n",
    "# Data point zero for the eight channels.  Should be in V.\n",
    "signal = mat['data'][0][0][0] \n",
    "print(f'Tamaño de {len(signal)}')\n",
    "#* pow(10,6)\n",
    "\n",
    "# Trials\n",
    "t_trials = mat['data'][0][0][3]\n",
    "\n",
    "# Flash matrix\n",
    "t_flash = mat['data'][0][0][4]\n",
    "\n",
    "signal = DrugSignal(signal, t_flash)\n",
    "\n",
    "t_stim = mat['data'][0][0][2]\n",
    "t_type = mat['data'][0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Tamaño de {len(t_trials)}')\n",
    "print(f'Tamaño de {len(t_flash)}')\n",
    "print(f'Tamaño de {len(t_stim)}')\n",
    "print(f'Tamaño de {len(t_type)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(t_type)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Acá puedo revisar esta guia -> [*Guía*](https://github.com/faturita/python-nerv/blob/master/MNE%20BNCI%20Horizon%202020%20Dataset%20008-2014.ipynb)    \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de DrugSignal.py, parte II  \n",
    "  \n",
    "En *a_analisis_funcion_DrugSignal.ipynb* se llega a drogar la señal con variaciones en la amplitud y fase.  \n",
    "A continuación la preparación de los datos para ser visualizados con la librería de python mne.  \n",
    "  \n",
    "[*Creating data objects from arrays. mne library*](https://mne.tools/stable/creating_from_arrays.html)  \n",
    "  \n",
    "- Una instancia básica de información llamada *info_events*:  \n",
    "Esta contiene el nombre de los canales, el ratio de muestreo y el canal de datos.  \n",
    "Para éste caso no se usará canal de datos, por eso se carga *ch_types_events* con ['misc'].  \n",
    "  \n",
    "- Un objeto \"en crudo\" a partir de un array de numpy llamado *eeg*.  \n",
    "\n",
    "- Un tercer objeto *event_times* que trae la info completa y además agrega el 't_type',\n",
    "profundizado en [*a_analisis_p300subject25_stim&type.ipynb*](a_analisis_p300subject25_stim&type.ipynb).\n",
    "\n",
    "Al finalizar, tendremos un objeto *eeg* que contiene todo:  \n",
    "La señal drogada, *t_stim* y *t_type* y sus respectivos eventos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_names=['Fz','Cz','P3','Pz','P4','PO7','PO8', 'Oz']                   # Los nombres de los canales\n",
    "ch_types= ['eeg'] * signal.shape[1]                                     # Un vector de tamaño 8 con el'eeg' repetido\n",
    "ch_names_events = ch_names + ['t_stim']+ ['t_type']                     # Le agrega  't_stim' y't_type' \n",
    "ch_types_events = ch_types + ['misc'] + ['misc']                        # Le agrega dos 'misc': \n",
    "                                                                        # Channel types, default is 'misc' which is not a data channel. \n",
    "                                                                        # Currently supported fields are ‘ecg’, ‘bio’, ‘stim’, ‘eog’, ‘misc’, \n",
    "                                                                        # ‘seeg’, ‘dbs’, ‘ecog’, ‘mag’, ‘eeg’, ‘ref_meg’, ‘grad’, ‘emg’, ‘hbr’ or ‘hbo’. \n",
    "                                                                        # If str, then all channels are assumed to be of the same type.\n",
    "#info = mne.create_info(ch_names, 250, ch_types=ch_types)\n",
    "#eeg_mne = mne.io.array.RawArray(signal.T, info)\n",
    "\n",
    "signal_events = np.concatenate([signal, t_stim, t_type],1)              # Se agrega a la señal drogada 't_stim' y 't_type'\n",
    "\n",
    "df_signal_events = a_fun.to_df(signal_events)\n",
    "ch_names_events_with_sample = ch_names_events + ['sample']\n",
    "df_signal_events.columns = ch_names_events_with_sample\n",
    "\n",
    "info_events = mne.create_info(ch_names_events,250, ch_types_events)     # Acá crea los eventos. \n",
    "eeg = mne.io.RawArray(signal_events.T, info_events)                     # El objeto en crudo.\n",
    "\n",
    "# Do some basic signal processing (1-20 band pass filter)\n",
    "# *** fig=eeg.plot_psd()\n",
    "eeg.filter(1,20)\n",
    "# *** fig=eeg.plot_psd()\n",
    "event_times = mne.find_events(eeg, stim_channel='t_type')    \n",
    "# *** eeg.plot(scalings='auto',n_channels=8,events=event_times,block=True)   # scalings=10e-05\n",
    "\n",
    "#========================================================================\n",
    "# ChatGPT:\n",
    "# Primero, verifica si la cantidad de valores únicos en la primera columna de la matriz es igual a 4200. \n",
    "# Si no es así, entonces el código busca valores duplicados en la primera columna de la matriz \n",
    "# y disminuye el valor de la fila correspondiente en 1 y establece el valor de la columna 1 en 1. \n",
    "# Luego, establece los valores de las columnas 2 y 3 de la matriz t_type y t_stim según los valores\n",
    "# correspondientes de la columna 3 y 2 de la matriz t_flash.\n",
    "# En la última línea del código, se utiliza la función assert para asegurarse de que la cantidad de valores únicos en la primera columna de la matriz t_flash sea igual a 4200. Si no lo es, se imprimirá un mensaje de error indicando que hay un problema con la estructura del experimento.\n",
    "\n",
    "if (np.unique(t_flash[:,0]).shape[0] != 4200):                          # evalúa si el \"sample point id\" de t_flash tiene el tamaño correcto.\n",
    "    u,c = np.unique( t_flash[:,0], return_counts=True)                  # u->Los elementos únicos. c->la cantidad de veces que se repiten.\n",
    "    dup = u[c>1]                                                        # dup->Los que estén repetidos mas de una vez.    \n",
    "    \n",
    "    for i in range(dup.shape[0]):\n",
    "        idx = np.where( t_flash[:,0] == dup[i] )[0][0]\n",
    "        t_flash[idx,0]  -= 1\n",
    "        t_flash[idx,1]  = 1\n",
    "        t_type[t_flash[idx,0]] = t_flash[idx,3]\n",
    "        t_stim[t_flash[idx,0]] = t_flash[idx,2]\n",
    "\n",
    "np.unique(t_flash[:,0]).shape\n",
    "assert  np.unique(t_flash[:,0]).shape[0] == 4200, 'Problem with experiment structure.  There aren''t enough events.'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gráficas de la señal con el ERP agregado y con *t_stim y t_type*.   \n",
    "La primera gráfica muestra el resultado general.    \n",
    "La segunda gráfica es cada una de las señales en un periodo de tiempo determinado.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(30,8))                                     \n",
    "#axes = plt.gca()\n",
    "#for i in range(0,9):\n",
    "#    plt.plot(df_signal_events['sample'], df_signal_events.iloc[:,i])\n",
    "#axes.set_title('DrugSignal con t_stim y t_type'), axes.title.set_size(30)\n",
    "#axes.set_xlabel(xlabel), axes.set_ylabel(ylabel)\n",
    "#axes.xaxis.label.set_size(20), axes.yaxis.label.set_size(20)\n",
    "#plt.savefig(\"./a_images/DrugSignal_p300subject25[data][0][0][0].jpg\")\n",
    "#plt.grid(), plt.show()\n",
    "                 \n",
    "\n",
    "xlim_general=([7000,15500])\n",
    "ylim_general=([-50,80])\n",
    "eje_x_sample=df_signal_events['sample']\n",
    "fig, (ax0, ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8, ax9) = plt.subplots(nrows=10, ncols=1,figsize=(30,20))\n",
    "fig.suptitle(\"DrugSignal con t_stim y t_type  \\n Eje x: muestra. Eje y: uV \", fontsize=30)\n",
    "\n",
    "ax0.plot(eje_x_sample, df_signal_events.iloc[:,0], label='0') \n",
    "ax0.set_xlim(xlim_general), ax0.set_ylim(ylim_general), ax0.set_title(df_signal_events.columns[0]), ax0.grid()\n",
    "\n",
    "ax1.plot(eje_x_sample, df_signal_events.iloc[:,1], label='1')\n",
    "ax1.set_xlim(xlim_general), ax1.set_ylim(ylim_general), ax1.set_title(df_signal_events.columns[1]), ax1.grid()\n",
    "\n",
    "ax2.plot(eje_x_sample, df_signal_events.iloc[:,2], label='2')\n",
    "ax2.set_xlim(xlim_general), ax2.set_ylim(ylim_general), ax2.set_title(df_signal_events.columns[2]), ax2.grid()\n",
    "\n",
    "ax3.plot(eje_x_sample, df_signal_events.iloc[:,3], label='3')\n",
    "ax3.set_xlim(xlim_general), ax3.set_ylim(ylim_general), ax3.set_title(df_signal_events.columns[3]), ax3.grid()\n",
    "\n",
    "ax4.plot(eje_x_sample, df_signal_events.iloc[:,4], label='4')\n",
    "ax4.set_xlim(xlim_general), ax4.set_ylim(ylim_general), ax4.set_title(df_signal_events.columns[4]), ax4.grid()\n",
    "\n",
    "ax5.plot(eje_x_sample, df_signal_events.iloc[:,5], label='5')\n",
    "ax5.set_xlim(xlim_general), ax5.set_ylim(ylim_general), ax4.set_title(df_signal_events.columns[5]), ax5.grid()\n",
    "\n",
    "ax6.plot(eje_x_sample, df_signal_events.iloc[:,6], label='6')\n",
    "ax6.set_xlim(xlim_general), ax6.set_ylim(ylim_general), ax6.set_title(df_signal_events.columns[6]), ax6.grid()\n",
    "\n",
    "ax7.plot(eje_x_sample, df_signal_events.iloc[:,7], label='7')\n",
    "ax7.set_xlim(xlim_general), ax7.set_ylim(ylim_general), ax7.set_title(df_signal_events.columns[7]), ax7.grid()\n",
    "\n",
    "ax8.plot(eje_x_sample, df_signal_events.iloc[:,8], label='8')\n",
    "ax8.set_xlim(xlim_general), ax8.set_ylim([-3,14]), ax8.set_title(df_signal_events.columns[8]), ax8.grid()\n",
    "\n",
    "ax9.plot(eje_x_sample, df_signal_events.iloc[:,9], label='9')\n",
    "ax9.set_xlim(xlim_general), ax9.set_ylim([-0.2,2.2]), ax9.set_title(df_signal_events.columns[9]), ax9.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones para obtener las estimulaciones y etiquetas.\n",
    "  \n",
    "#### getstims.  \n",
    "La función usa *info*, que es creada con los nombres de los canales (ch_names), la frecuencia de muestreo (259) y los tipos de canales ch_types.  También toma como entrada *eeg_mne*; es la traspuesta de signal e info.\n",
    "\n",
    "El resultado *event_times* es llamando a la función *find_events* de mne, que encuentra eventos del archivo \"raw\".  \n",
    "\n",
    "[*\"Find events\"*](https://mne.tools/stable/generated/mne.find_events.html)  \n",
    "\n",
    "\n",
    "[*\"Épocas: INVESTIGAR. NO ENTENDI NADA\"*](https://mne.tools/stable/generated/mne.Epochs.html#mne-epochs)\n",
    "\n",
    "#### getlabels.\n",
    "\n",
    "- Una instancia básica de información llamada *info_events*:  \n",
    "Esta contiene el nombre de los canales, el ratio de muestreo y el canal de datos.  \n",
    "Para éste caso no se usará canal de datos, por eso se carga *ch_types_events* con ['misc'].  \n",
    "  \n",
    "- Un objeto \"en crudo\" a partir de un array de numpy llamado *eeg*.  \n",
    "\n",
    "- Un tercer objeto *event_times* que trae la info completa y además agrega el 't_type',\n",
    "profundizado en [*a_analisis_p300subject25_stim&type.ipynb*](a_analisis_p300subject25_stim&type.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================================\n",
    "# getstims recibe dos argumentos: eeg_mne y eeg_events. eeg_mne debe ser un objeto de tipo MNE Raw o Epochs, \n",
    "# mientras que eeg_events debe ser un objeto que contenga los eventos relacionados con la señal EEG.\n",
    "# La función utiliza la biblioteca MNE de Python para encontrar los eventos en la señal EEG y crear epochs de 0 a 0.8 segundos de duración, \n",
    "# a partir de los eventos encontrados. Luego, la función extrae las marcas de tiempo de los eventos y las devuelve como una lista junto \n",
    "# con los epochs.\n",
    "\n",
    "# En resumen, la función getstims extrae los estímulos de una señal EEG y devuelve una lista de epochs y las marcas de tiempo de los eventos \n",
    "# relacionados con la señal.\n",
    "\n",
    "def getstims(eeg_mne, eeg_events):\n",
    "    '''\n",
    "    Get the stimulations.  These are the FLASHINGS of rows and columns.\n",
    "    '''\n",
    "    tmin = 0\n",
    "    tmax = 0.8\n",
    "    reject = None\n",
    "    event_times = mne.find_events(eeg_events, stim_channel='t_stim',shortest_event=0, verbose=True, min_duration=0.000001, consecutive=True)\n",
    "    event_id = {'Row1':1,'Row2':2,'Row3':3,'Row4':4,'Row5':5,'Row6':6,'Col1':7,'Col2':8,'Col3':9,'Col4':10,'Col5':11,'Col6':12}\n",
    "\n",
    "\n",
    "    epochs = mne.Epochs(eeg_mne, event_times, event_id, tmin, tmax, proj=False,\n",
    "                    baseline=None, reject=reject, preload=True,\n",
    "                    verbose=True, reject_by_annotation=None)\n",
    "\n",
    "\n",
    "    stims = event_times[:,-1]\n",
    "\n",
    "    return [epochs,stims]\n",
    "\n",
    "stimepochs, stims = getstims(eeg, eeg)                                  # Época de estimulación.\n",
    "stimepochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================================\n",
    "# ChatGPT:\n",
    "# La función getlabels recibe tres argumentos: eeg_mne, eeg_events y event_id. eeg_mne debe ser un objeto de tipo MNE Raw o Epochs, \n",
    "# mientras que eeg_events debe ser un objeto que contenga los eventos relacionados con la señal EEG.\n",
    "# La función utiliza la biblioteca MNE de Python para encontrar los eventos en la señal EEG y crear epochs de 0 a 0.8 segundos de duración, \n",
    "# a partir de los eventos encontrados. Luego, la función extrae las marcas de tiempo de los eventos y las devuelve como una lista junto \n",
    "# con los epochs.\n",
    "\n",
    "# En resumen, la función getstims extrae los estímulos de una señal EEG y devuelve una lista de epochs y las marcas de tiempo de los eventos \n",
    "# relacionados con la señal.\n",
    "\n",
    "\n",
    "def getlabels(eeg_mne, eeg_events, event_id):\n",
    "    '''\n",
    "    Get the hit/no hits labels.  These are the FLASHINGS of rows and columns but selected if they are the ones that will\n",
    "    trigger the P300 response or not.\n",
    "    '''\n",
    "    #event_id = { 'first':1, 'second':2 }\n",
    "    #baseline = (0.0, 0.2)\n",
    "    #reject = {'eeg': 70 * pow(10,6)}\n",
    "    tmin = 0\n",
    "    tmax = 0.8\n",
    "    reject = None\n",
    "    event_times = mne.find_events(eeg_events, stim_channel='t_type', shortest_event=0, verbose=True, min_duration=0.000001, consecutive=True)\n",
    "    epochs = mne.Epochs(eeg_mne, event_times, event_id, tmin, tmax, proj=False,\n",
    "                    baseline=None, reject=reject, preload=True,\n",
    "                    verbose=True, reject_by_annotation=None)\n",
    "    labels = epochs.events[:, -1]\n",
    "    return [epochs, labels]\n",
    "\n",
    "epochs, labels = getlabels(eeg, eeg, {'first':1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epocked = epochs.average()\n",
    "epocked.plot(window_title='NoHit Averaged Signals')\n",
    "\n",
    "\n",
    "epochs, labels = getlabels(eeg, eeg, {'second':2})\n",
    "\n",
    "epocked = epochs.average()\n",
    "epocked.plot(window_title='Hit Averaged Signals')\n",
    "\n",
    "epochs, labels = getlabels(eeg, eeg, { 'first':1, 'second':2})\n",
    "\n",
    "\n",
    "# Downsample the original FS=250 Hz signal to >>> 20 Hz\n",
    "#epochs.resample(20, npad=\"auto\")\n",
    "#stimepochs.resample(20, npad=\"auto\")\n",
    "repetitions=120"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b958d2ee4113081da5b7324adcb012071bef3fd829261c203699a43a2ce6bc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
