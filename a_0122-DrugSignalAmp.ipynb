{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc8c604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# Implementación del vector de 5 templates ERP con distintas variaciones en amplitud:\n",
    "# +/- 20% del valor max y min del ERPtemplate original.\n",
    "# ==================================================\n",
    "import mne                                                              \n",
    "mne.set_log_level('WARNING')                                            \n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb                                                    \n",
    "\n",
    "import a_funciones as a_fun  \n",
    "import random\n",
    "\n",
    "color = ['green', 'blue','red','cyan', 'magenta', 'yellow','brown','k']     # Paleta de colores para diferenciar las ondas\n",
    "xlabel = 'Muestra'\n",
    "ylabel = 'Amplitud (uV)'\n",
    "\n",
    "mat = scipy.io.loadmat('./dataset/ERPTemplate.mat')\n",
    "routput = mat['routput']\n",
    "erptemplate1 = routput[0][7][0][1][0][0][0][7]                          \n",
    "erptemplate1 = np.delete(erptemplate1, range(0,256,43),0)              \n",
    "#-----------------------------------------------------------------------\n",
    "# array_DrugAmpERPtemplate es un vector de 5 templates ERP con \n",
    "# distintas variaciones en amplitud +/- 20% del valor max y min del ERPtemplate original\n",
    "#-----------------------------------------------------------------------\n",
    "porcentaje = 0.02\n",
    "v_min = erptemplate1.min()-(erptemplate1.min()*porcentaje)\n",
    "v_max = erptemplate1.max()+(erptemplate1.max()*porcentaje)\n",
    "\n",
    "array_DrugAmpERPtemplate = np.empty(5,dtype=object)\n",
    "for i in range(5):\n",
    "    v_aleatorio = np.random.uniform(v_min, v_max, (1, 8)) \n",
    "    #print(f'v_aleatorio({i}): ',v_aleatorio)\n",
    "    # v_aleatorio = [-5,1,5,0,5,0,5,0] # Vector fijo para testing\n",
    "    DrugAmpERPtemplate = np.empty_like(erptemplate1) # Inicializo un array igual que erptemplate1\n",
    "    for j in range(erptemplate1.shape[0]):\n",
    "        DrugAmpERPtemplate[j, :] = erptemplate1[j, :] + v_aleatorio\n",
    "    array_DrugAmpERPtemplate[i] = DrugAmpERPtemplate\n",
    "    #print(f'array_DrugAmpERPtemplate[{i}].min()', array_DrugAmpERPtemplate[i].min())\n",
    "    #print(f'array_DrugAmpERPtemplate[{i}].max()', array_DrugAmpERPtemplate[i].max())\n",
    "    #print('----------------------------------------------------')\n",
    "\n",
    "# print('array_DrugAmpERPtemplate.shape:',array_DrugAmpERPtemplate[1].shape)\n",
    "# print('array_DrugAmpERPtemplate:',array_DrugAmpERPtemplate)\n",
    "# ch_names=['Fz','Cz','P3','Pz','P4','PO7','PO8', 'Oz'] # Nombres de los canales\n",
    "# np.save('./dataset/array_DrugAmpERPtemplate.npy', array_DrugAmpERPtemplate)\n",
    "np.save('./dataset/DrugAmpERPtemplate.npy', array_DrugAmpERPtemplate[1])\n",
    "# Cargar el array desde el archivo: array_cargado = np.load('mi_array.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28e9e391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4040 events found\n",
      "Event IDs: [ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "Not setting metadata\n",
      "4040 matching events found\n",
      "No baseline correction applied\n",
      "Using data from preloaded Raw for 4040 events and 201 original time points ...\n",
      "0 bad epochs dropped\n",
      "4004 events found\n",
      "Event IDs: [1 2]\n",
      "Not setting metadata\n",
      "3333 matching events found\n",
      "No baseline correction applied\n",
      "Using data from preloaded Raw for 3333 events and 201 original time points ...\n",
      "0 bad epochs dropped\n",
      "4004 events found\n",
      "Event IDs: [1 2]\n",
      "Not setting metadata\n",
      "671 matching events found\n",
      "No baseline correction applied\n",
      "Using data from preloaded Raw for 671 events and 201 original time points ...\n",
      "0 bad epochs dropped\n",
      "4004 events found\n",
      "Event IDs: [1 2]\n",
      "Not setting metadata\n",
      "4004 matching events found\n",
      "No baseline correction applied\n",
      "Using data from preloaded Raw for 4004 events and 201 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hlbls: 33\n",
      "9_944___9_____9_________4___9_4_2\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 0\n",
      "De dónde [:]: 0\n",
      "A dónde [:]: 120\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 1\n",
      "De dónde [:]: 120\n",
      "A dónde [:]: 240\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 2\n",
      "De dónde [:]: 240\n",
      "A dónde [:]: 360\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 3\n",
      "De dónde [:]: 360\n",
      "A dónde [:]: 480\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 4\n",
      "De dónde [:]: 480\n",
      "A dónde [:]: 600\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 5\n",
      "De dónde [:]: 600\n",
      "A dónde [:]: 720\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 6\n",
      "De dónde [:]: 720\n",
      "A dónde [:]: 840\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 7\n",
      "De dónde [:]: 840\n",
      "A dónde [:]: 960\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 8\n",
      "De dónde [:]: 960\n",
      "A dónde [:]: 1080\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 9\n",
      "De dónde [:]: 1080\n",
      "A dónde [:]: 1200\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 10\n",
      "De dónde [:]: 1200\n",
      "A dónde [:]: 1320\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 11\n",
      "De dónde [:]: 1320\n",
      "A dónde [:]: 1440\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 12\n",
      "De dónde [:]: 1440\n",
      "A dónde [:]: 1560\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 13\n",
      "De dónde [:]: 1560\n",
      "A dónde [:]: 1680\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 14\n",
      "De dónde [:]: 1680\n",
      "A dónde [:]: 1800\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 15\n",
      "De dónde [:]: 1800\n",
      "A dónde [:]: 1920\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 16\n",
      "De dónde [:]: 1920\n",
      "A dónde [:]: 2040\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 17\n",
      "De dónde [:]: 2040\n",
      "A dónde [:]: 2160\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 18\n",
      "De dónde [:]: 2160\n",
      "A dónde [:]: 2280\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 19\n",
      "De dónde [:]: 2280\n",
      "A dónde [:]: 2400\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 20\n",
      "De dónde [:]: 2400\n",
      "A dónde [:]: 2520\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 21\n",
      "De dónde [:]: 2520\n",
      "A dónde [:]: 2640\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 22\n",
      "De dónde [:]: 2640\n",
      "A dónde [:]: 2760\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 23\n",
      "De dónde [:]: 2760\n",
      "A dónde [:]: 2880\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 24\n",
      "De dónde [:]: 2880\n",
      "A dónde [:]: 3000\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 25\n",
      "De dónde [:]: 3000\n",
      "A dónde [:]: 3120\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 26\n",
      "De dónde [:]: 3120\n",
      "A dónde [:]: 3240\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 27\n",
      "De dónde [:]: 3240\n",
      "A dónde [:]: 3360\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 28\n",
      "De dónde [:]: 3360\n",
      "A dónde [:]: 3480\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 29\n",
      "De dónde [:]: 3480\n",
      "A dónde [:]: 3600\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 30\n",
      "De dónde [:]: 3600\n",
      "A dónde [:]: 3720\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 31\n",
      "De dónde [:]: 3720\n",
      "A dónde [:]: 3840\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 32\n",
      "De dónde [:]: 3840\n",
      "A dónde [:]: 3960\n",
      "Performance Classification of Averaged Epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_9_________4___9_4_2\n",
      "JY7TC6JRNW9J3_U8NI12\n",
      "-----------------------------------------\n",
      "Accuracy: 0.8185840707964602\n",
      "-----------------------------------------\n",
      "4065 events found\n",
      "Event IDs: [ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "Not setting metadata\n",
      "4065 matching events found\n",
      "No baseline correction applied\n",
      "Using data from preloaded Raw for 4065 events and 201 original time points ...\n",
      "2 bad epochs dropped\n",
      "4018 events found\n",
      "Event IDs: [1 2]\n",
      "Not setting metadata\n",
      "3337 matching events found\n",
      "No baseline correction applied\n",
      "Using data from preloaded Raw for 3337 events and 201 original time points ...\n",
      "2 bad epochs dropped\n",
      "4018 events found\n",
      "Event IDs: [1 2]\n",
      "Not setting metadata\n",
      "681 matching events found\n",
      "No baseline correction applied\n",
      "Using data from preloaded Raw for 681 events and 201 original time points ...\n",
      "0 bad epochs dropped\n",
      "4018 events found\n",
      "Event IDs: [1 2]\n",
      "Not setting metadata\n",
      "4018 matching events found\n",
      "No baseline correction applied\n",
      "Using data from preloaded Raw for 4018 events and 201 original time points ...\n",
      "2 bad epochs dropped\n",
      "hlbls: 33\n",
      "__4_44948__4_____9___9___________\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 0\n",
      "De dónde [:]: 0\n",
      "A dónde [:]: 120\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 1\n",
      "De dónde [:]: 120\n",
      "A dónde [:]: 240\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 2\n",
      "De dónde [:]: 240\n",
      "A dónde [:]: 360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 3\n",
      "De dónde [:]: 360\n",
      "A dónde [:]: 480\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 4\n",
      "De dónde [:]: 480\n",
      "A dónde [:]: 600\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 5\n",
      "De dónde [:]: 600\n",
      "A dónde [:]: 720\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 6\n",
      "De dónde [:]: 720\n",
      "A dónde [:]: 840\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 7\n",
      "De dónde [:]: 840\n",
      "A dónde [:]: 960\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 8\n",
      "De dónde [:]: 960\n",
      "A dónde [:]: 1080\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 9\n",
      "De dónde [:]: 1080\n",
      "A dónde [:]: 1200\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 10\n",
      "De dónde [:]: 1200\n",
      "A dónde [:]: 1320\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 11\n",
      "De dónde [:]: 1320\n",
      "A dónde [:]: 1440\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 12\n",
      "De dónde [:]: 1440\n",
      "A dónde [:]: 1560\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 13\n",
      "De dónde [:]: 1560\n",
      "A dónde [:]: 1680\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 14\n",
      "De dónde [:]: 1680\n",
      "A dónde [:]: 1800\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 15\n",
      "De dónde [:]: 1800\n",
      "A dónde [:]: 1920\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 16\n",
      "De dónde [:]: 1920\n",
      "A dónde [:]: 2040\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 17\n",
      "De dónde [:]: 2040\n",
      "A dónde [:]: 2160\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 18\n",
      "De dónde [:]: 2160\n",
      "A dónde [:]: 2280\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 19\n",
      "De dónde [:]: 2280\n",
      "A dónde [:]: 2400\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 20\n",
      "De dónde [:]: 2400\n",
      "A dónde [:]: 2520\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 21\n",
      "De dónde [:]: 2520\n",
      "A dónde [:]: 2640\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 22\n",
      "De dónde [:]: 2640\n",
      "A dónde [:]: 2760\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 23\n",
      "De dónde [:]: 2760\n",
      "A dónde [:]: 2880\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 24\n",
      "De dónde [:]: 2880\n",
      "A dónde [:]: 3000\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 25\n",
      "De dónde [:]: 3000\n",
      "A dónde [:]: 3120\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 26\n",
      "De dónde [:]: 3120\n",
      "A dónde [:]: 3240\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 27\n",
      "De dónde [:]: 3240\n",
      "A dónde [:]: 3360\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 28\n",
      "De dónde [:]: 3360\n",
      "A dónde [:]: 3480\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 29\n",
      "De dónde [:]: 3480\n",
      "A dónde [:]: 3600\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 30\n",
      "De dónde [:]: 3600\n",
      "A dónde [:]: 3720\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 31\n",
      "De dónde [:]: 3720\n",
      "A dónde [:]: 3840\n",
      "Cantidad de letras seleccionadas: 33\n",
      "Posición de la letra: 32\n",
      "De dónde [:]: 3840\n",
      "A dónde [:]: 3960\n",
      "Performance Classification of Averaged Epochs\n",
      "____9___9___________\n",
      "IO3P6KBD1_RBQLFMGAKN\n",
      "-----------------------------------------\n",
      "Accuracy: 0.7477876106194691\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3963 events found\n",
      "Event IDs: [ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "Not setting metadata\n",
      "3963 matching events found\n",
      "No baseline correction applied\n",
      "Using data from preloaded Raw for 3963 events and 201 original time points ...\n",
      "2 bad epochs dropped\n",
      "3894 events found\n",
      "Event IDs: [1 2]\n",
      "Not setting metadata\n",
      "3239 matching events found\n",
      "No baseline correction applied\n",
      "Using data from preloaded Raw for 3239 events and 201 original time points ...\n",
      "2 bad epochs dropped\n",
      "3894 events found\n",
      "Event IDs: [1 2]\n",
      "Not setting metadata\n",
      "655 matching events found\n",
      "No baseline correction applied\n",
      "Using data from preloaded Raw for 655 events and 201 original time points ...\n",
      "0 bad epochs dropped\n",
      "3894 events found\n",
      "Event IDs: [1 2]\n",
      "Not setting metadata\n",
      "3894 matching events found\n",
      "No baseline correction applied\n",
      "Using data from preloaded Raw for 3894 events and 201 original time points ...\n",
      "2 bad epochs dropped\n",
      "hlbls: 32\n",
      "___4___44__9_9___9__94____4_9___\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 0\n",
      "De dónde [:]: 0\n",
      "A dónde [:]: 120\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 1\n",
      "De dónde [:]: 120\n",
      "A dónde [:]: 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 2\n",
      "De dónde [:]: 240\n",
      "A dónde [:]: 360\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 3\n",
      "De dónde [:]: 360\n",
      "A dónde [:]: 480\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 4\n",
      "De dónde [:]: 480\n",
      "A dónde [:]: 600\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 5\n",
      "De dónde [:]: 600\n",
      "A dónde [:]: 720\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 6\n",
      "De dónde [:]: 720\n",
      "A dónde [:]: 840\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 7\n",
      "De dónde [:]: 840\n",
      "A dónde [:]: 960\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 8\n",
      "De dónde [:]: 960\n",
      "A dónde [:]: 1080\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 9\n",
      "De dónde [:]: 1080\n",
      "A dónde [:]: 1200\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 10\n",
      "De dónde [:]: 1200\n",
      "A dónde [:]: 1320\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 11\n",
      "De dónde [:]: 1320\n",
      "A dónde [:]: 1440\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 12\n",
      "De dónde [:]: 1440\n",
      "A dónde [:]: 1560\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 13\n",
      "De dónde [:]: 1560\n",
      "A dónde [:]: 1680\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 14\n",
      "De dónde [:]: 1680\n",
      "A dónde [:]: 1800\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 15\n",
      "De dónde [:]: 1800\n",
      "A dónde [:]: 1920\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 16\n",
      "De dónde [:]: 1920\n",
      "A dónde [:]: 2040\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 17\n",
      "De dónde [:]: 2040\n",
      "A dónde [:]: 2160\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 18\n",
      "De dónde [:]: 2160\n",
      "A dónde [:]: 2280\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 19\n",
      "De dónde [:]: 2280\n",
      "A dónde [:]: 2400\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 20\n",
      "De dónde [:]: 2400\n",
      "A dónde [:]: 2520\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 21\n",
      "De dónde [:]: 2520\n",
      "A dónde [:]: 2640\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 22\n",
      "De dónde [:]: 2640\n",
      "A dónde [:]: 2760\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 23\n",
      "De dónde [:]: 2760\n",
      "A dónde [:]: 2880\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 24\n",
      "De dónde [:]: 2880\n",
      "A dónde [:]: 3000\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 25\n",
      "De dónde [:]: 3000\n",
      "A dónde [:]: 3120\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 26\n",
      "De dónde [:]: 3120\n",
      "A dónde [:]: 3240\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 27\n",
      "De dónde [:]: 3240\n",
      "A dónde [:]: 3360\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 28\n",
      "De dónde [:]: 3360\n",
      "A dónde [:]: 3480\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 29\n",
      "De dónde [:]: 3480\n",
      "A dónde [:]: 3600\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 30\n",
      "De dónde [:]: 3600\n",
      "A dónde [:]: 3720\n",
      "Cantidad de letras seleccionadas: 32\n",
      "Posición de la letra: 31\n",
      "De dónde [:]: 3720\n",
      "A dónde [:]: 3840\n",
      "Performance Classification of Averaged Epochs\n",
      "_9___9__94____4_9___\n",
      "DTY_97O6XOBRAFUWHKCA\n",
      "-----------------------------------------\n",
      "Accuracy: 0.7853881278538812\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6836/1884675525.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mfile_temp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults_mne\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"a\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;31m# print(f'P{ii+1},', file=file_temp) # COLUMNA0.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mpunto_mat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;31m# Data point zero for the eight channels.  Should be in V.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alexc\\anaconda3\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[0mMR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mmatfile_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmdict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alexc\\anaconda3\\lib\\site-packages\\scipy\\io\\matlab\\mio5.py\u001b[0m in \u001b[0;36mget_variables\u001b[1;34m(self, variable_names)\u001b[0m\n\u001b[0;32m    330\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_var_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhdr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mMatReadError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m                 warnings.warn(\n",
      "\u001b[1;32mc:\\Users\\alexc\\anaconda3\\lib\\site-packages\\scipy\\io\\matlab\\mio5.py\u001b[0m in \u001b[0;36mread_var_array\u001b[1;34m(self, header, process)\u001b[0m\n\u001b[0;32m    290\u001b[0m            \u001b[0;31m`\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         '''\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_matrix_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_from_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariable_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# Este es el código que replica el experimento.\n",
    "# Calcula el Accuracy final para P300S01, 02, 03 y 06.mat. \n",
    "# No todos los EEGs contienen 35 letras y 420 eventos.\n",
    "# Hice cambios en training y test.\n",
    "# ==================================================\n",
    "import mne\n",
    "mne.set_log_level('WARNING')\n",
    "\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "\n",
    "# Randomize amplitude and jitter.\n",
    "# Find the right locations where this should be inserted in the stream.\n",
    "# Insert the signal mantaining the continiuity of the EEG.\n",
    "def DrugSignal(signal, t_flash):\n",
    "    '''\n",
    "    Randomize amplitude and jitter\n",
    "    Find the right locations where this should be inserted in the stream\n",
    "    Insert the template mantaining the continuity and physiological meaning of the EEG\n",
    "    '''\n",
    "    for i in range(0,4200):\n",
    "        if (t_flash[i,3]==2):\n",
    "            signal[t_flash[i,0]-1:t_flash[i,0]+250-1,:] += (erptemplate1)\n",
    "    return signal\n",
    "\n",
    "# Now load the basal EEG stream\n",
    "# mat = scipy.io.loadmat('./dataset/p300-subject-25.mat')\n",
    "# mat = scipy.io.loadmat('./dataset/itba/P300S02.mat')\n",
    "files_path_itba = ['./dataset/itba/P300S01.mat', './dataset/itba/P300S02.mat', \n",
    "                    './dataset/itba/P300S03.mat', './dataset/itba/P300S06.mat']\n",
    "\n",
    "repetitions = 120\n",
    "\n",
    "for ii, path in enumerate(files_path_itba):  \n",
    "    erptemplate1 = np.load('./dataset/DrugAmpERPtemplate.npy')\n",
    "    results_mne=f'./a_results/20240201AMP.csv' # Si necesitás, con cambiar la extensión a.txt es suficiente\n",
    "    file_temp=open(results_mne,\"a\") \n",
    "    # print(f'P{ii+1},', file=file_temp) # COLUMNA0.\n",
    "    punto_mat=scipy.io.loadmat(path)\n",
    "\n",
    "    # Data point zero for the eight channels.  Should be in V.\n",
    "    signal = punto_mat['data'][0][0][0] \n",
    "    #* pow(10,6)\n",
    "\n",
    "    # Trials\n",
    "    t_trials = punto_mat['data'][0][0][3]\n",
    "\n",
    "    # Flash matrix\n",
    "    t_flash = punto_mat['data'][0][0][4]\n",
    "\n",
    "    signal = DrugSignal(signal, t_flash)\n",
    "\n",
    "    t_stim = punto_mat['data'][0][0][2]\n",
    "    t_type = punto_mat['data'][0][0][1]\n",
    "\n",
    "    ch_names=[ 'Fz'  ,  'Cz',    'P3' ,   'Pz'  ,  'P4'  ,  'PO7'   , 'PO8'   , 'Oz']\n",
    "    ch_types= ['eeg'] * signal.shape[1]\n",
    "\n",
    "    ch_names_events = ch_names + ['t_stim']+ ['t_type']\n",
    "    ch_types_events = ch_types + ['misc'] + ['misc']\n",
    "\n",
    "    #info = mne.create_info(ch_names, 250, ch_types=ch_types)\n",
    "    #eeg_mne = mne.io.array.RawArray(signal.T, info)\n",
    "\n",
    "    signal_events = np.concatenate([signal, t_stim, t_type],1)\n",
    "    info_events = mne.create_info(ch_names_events,250, ch_types_events)\n",
    "    eeg = mne.io.RawArray(signal_events.T, info_events)\n",
    "\n",
    "    # Do some basic signal processing (1-20 band pass filter)\n",
    "    # fig=eeg.plot_psd()\n",
    "    eeg.filter(1,20)\n",
    "    # fig=eeg.plot_psd()\n",
    "    event_times = mne.find_events(eeg, stim_channel='t_type')    \n",
    "    # eeg.plot(scalings='auto',n_channels=8,events=event_times,block=True)   # scalings=10e-05\n",
    "\n",
    "    if (np.unique(t_flash[:,0]).shape[0] != 4200):\n",
    "        u,c = np.unique( t_flash[:,0], return_counts=True)\n",
    "        dup = u[c>1]\n",
    "        for i in range(dup.shape[0]):\n",
    "            idx = np.where( t_flash[:,0] == dup[i] )[0][0]\n",
    "            t_flash[idx,0]  -= 1\n",
    "            t_flash[idx,1]  = 1\n",
    "            t_type[t_flash[idx,0]] = t_flash[idx,3]\n",
    "            t_stim[t_flash[idx,0]] = t_flash[idx,2]\n",
    "\n",
    "    np.unique(t_flash[:,0]).shape\n",
    "    assert  np.unique(t_flash[:,0]).shape[0] == 4200, 'Problem with experiment structure.  There aren''t enough events.'\n",
    "\n",
    "    def getstims(eeg_mne, eeg_events):\n",
    "        # Get the stimulations.  These are the FLASHINGS of rows and columns.\n",
    "        tmin = 0\n",
    "        tmax = 0.8\n",
    "        reject = None\n",
    "        event_times = mne.find_events(eeg_events, stim_channel='t_stim',shortest_event=0, verbose=True, min_duration=0.000001, consecutive=True)\n",
    "        event_id = {'Row1':1,'Row2':2,'Row3':3,'Row4':4,'Row5':5,'Row6':6,'Col1':7,'Col2':8,'Col3':9,'Col4':10,'Col5':11,'Col6':12}\n",
    "\n",
    "        epochs = mne.Epochs(eeg_mne, event_times, event_id, tmin, tmax, proj=False,\n",
    "                        baseline=None, reject=reject, preload=True,\n",
    "                        verbose=True, reject_by_annotation=None)\n",
    "\n",
    "        stims = event_times[:,-1]\n",
    "        return [epochs,stims]\n",
    "\n",
    "    stimepochs, stims = getstims(eeg, eeg)\n",
    "\n",
    "    def getlabels(eeg_mne, eeg_events, event_id):\n",
    "        # Get the hit/no hits labels.  \n",
    "        # These are the FLASHINGS of rows and columns but selected if they are the ones that will trigger the P300 response or not.\n",
    "        # event_id = { 'first':1, 'second':2 }\n",
    "        # baseline = (0.0, 0.2)\n",
    "        # reject = {'eeg': 70 * pow(10,6)}\n",
    "        tmin = 0\n",
    "        tmax = 0.8\n",
    "        reject = None\n",
    "        event_times = mne.find_events(eeg_events, stim_channel='t_type', shortest_event=0, verbose=True, min_duration=0.000001, consecutive=True)\n",
    "        epochs = mne.Epochs(eeg_mne, event_times, event_id, tmin, tmax, proj=False,\n",
    "                        baseline=None, reject=reject, preload=True,\n",
    "                        verbose=True, reject_by_annotation=None)\n",
    "        labels = epochs.events[:, -1]\n",
    "        return [epochs, labels]\n",
    "\n",
    "    epochs, labels = getlabels(eeg, eeg, {'first':1})\n",
    "    epocked = epochs.average()\n",
    "    # epocked.plot(window_title='NoHit Averaged Signals')\n",
    "    epochs, labels = getlabels(eeg, eeg, {'second':2})\n",
    "    epocked = epochs.average()\n",
    "    # epocked.plot(window_title='Hit Averaged Signals')\n",
    "    epochs, labels = getlabels(eeg, eeg, { 'first':1, 'second':2})\n",
    "\n",
    "    # Downsample the original FS=250 Hz signal to >>> 20 Hz\n",
    "    #epochs.resample(20, npad=\"auto\")\n",
    "    #stimepochs.resample(20, npad=\"auto\")\n",
    "    # repetitions = 120\n",
    "    # Con 100: El clasificador da resultados distintos.\n",
    "    # %%\n",
    "    # This is Single Flashing Classification attempt.\n",
    "    from sklearn.preprocessing import  StandardScaler\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn import svm\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    # import a linear classifier from mne.decoding\n",
    "    from mne.decoding import LinearModel\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    clf = LogisticRegression(solver='lbfgs')\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # create a linear model with LogisticRegression\n",
    "    model = LinearModel(clf)\n",
    "\n",
    "    # Get the epoched data (get only the data columns)\n",
    "    eeg_data = epochs.get_data().reshape(len(labels), -1)\n",
    "    eeg_data = eeg_data[:,0:epochs.get_data().shape[2]*1]\n",
    "    #eeg_data[labels==2] = erptemplate1[:201,0]\n",
    "    #eeg_data[labels==1] = erptemplate1[:201,0]\n",
    "    #eeg_data[labels==2] = np.zeros((eeg_data.shape[1],))\n",
    "    #eeg_data[labels==1] = np.ones((eeg_data.shape[1],))\n",
    "    #labels = np.random.permutation(labels)\n",
    "\n",
    "    # fit the classifier on MEG data\n",
    "    X = scaler.fit_transform(eeg_data)\n",
    "\n",
    "    model.fit(X[0:2800], labels[0:2800])\n",
    "\n",
    "    preds = model.predict(X[2800:])\n",
    "\n",
    "    # Classification report\n",
    "    target_names = ['nohit', 'hit']\n",
    "\n",
    "    report = classification_report(labels[2800:], preds, target_names=target_names)\n",
    "    # print(report)\n",
    "\n",
    "    cm = confusion_matrix(labels[2800:], preds)\n",
    "    # print (cm)\n",
    "    cm_normalized = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis]\n",
    "    acc=(cm[0,0]+cm[1,1])*1.0/(np.sum(cm))\n",
    "\n",
    "    '''\n",
    "    import matplotlib.pyplot as plt\n",
    "    for i in range(200,220):\n",
    "        plt.figure(figsize=(9, 3))\n",
    "        plt.plot(eeg_data[labels==1][i])\n",
    "        plt.show()\n",
    "    '''\n",
    "\n",
    "    # In[1]:   Average classification x trial (unbalanced)\n",
    "    # Este dataset es un dataset de calibración. El registro de EEG corresponde a un experimento del Speller\n",
    "    # de 35 letras (7 palabras de 5 letras).   Cada una de las letras consiste en 10 repeticiones de la intensificación \n",
    "    # de los 12 estímulos distintos, siendo cada estímulo el FLASHING de una de las 6 filas o 6 columnas.\n",
    "    # Cada vez que se repite, se hace una permutación de los 12.\n",
    "    # En cada una de esos 12 estímulos, dos, uno correspondiente a una fila y a una columna, corresponden \n",
    "    # a la letra que la persona está prestando atención y la idea es que el sistema descubra que letra es.\n",
    "\n",
    "    # Primero tengo que agarrar la lista de labels y asignar a los 420 (35x12)\n",
    "    # el label que le corresponde a cada uno.  Es decir de los primeros 12, 10\n",
    "    # son no hits y 2 hits.\n",
    "\n",
    "    # hlbls tiene pares (r,c) que representan la fila y la columna donde está la letra\n",
    "    # que la persona tiene que elegir. \n",
    "    hlbls = []\n",
    "    hpreds = []\n",
    "    classlabels=np.asarray([])\n",
    "\n",
    "    # ==================================================\n",
    "    redondeo_hlbls = int((abs(min(len(stims), len(labels))))/120)\n",
    "    print(\"hlbls:\", redondeo_hlbls)\n",
    "    # Este cálculo se hace porque no todos los resultados son iguales:\n",
    "    # Paciente\t            hlbls\tEventos\n",
    "    # P300S01.mat\t        33\t    396\n",
    "    # P300S02.mat\t        33\t    396\n",
    "    # P300S03.mat\t        32\t    384\n",
    "    # P300S04.mat\t        32\t    384\n",
    "    # P300S05.mat\t        33\t    396\n",
    "    # P300S06.mat\t        32\t    384\n",
    "    # P300S07.mat\t        32\t    384\n",
    "    # P300S08.mat\t        32\t    384\n",
    "    #p300-subject-25.mat\t35\t    420\n",
    "    # ==================================================\n",
    "\n",
    "    for trial in range(0,redondeo_hlbls):\n",
    "        # a=np.zeros((12*10,2))\n",
    "        # a[:,0] = stims[0+120*trial:0+120*trial+120]\n",
    "        # a[:,1] = labels[0+120*trial:0+120*trial+120]    \n",
    "        \n",
    "        a=np.zeros((repetitions,2))\n",
    "        # a[:,0] = stims[0+repetitions*trial:0+repetitions*trial+repetitions]\n",
    "        # a[:,1] = labels[0+repetitions*trial:0+repetitions*trial+repetitions]    \n",
    "\n",
    "        a[:,0] = stims[0+repetitions*trial:0+repetitions*trial+repetitions]\n",
    "        a[:,1] = labels[0+repetitions*trial:0+repetitions*trial+repetitions]    \n",
    "        # print(\"a[:,0]:\", a[:,0])\n",
    "        # print(len(a[:,0]))\n",
    "            \n",
    "        # b=np.zeros((12,1))\n",
    "        b=np.zeros((12,2))\n",
    "        \n",
    "        for i in range(1,13):\n",
    "            # print(\"Resultado final de b[] dos filas\", b)\n",
    "            if (len(np.unique(a[a[:,0]==i,1]))==0):\n",
    "                b[i-1] = [0, 0]\n",
    "                # print(\"Cuando b[] tiene tamaño CERO:\", b)\n",
    "            else: \n",
    "                # print(\"+++++++++++++++++++++++++++++++++\")  \n",
    "                # print(\"Longitud del array de valores únicos\", len(np.unique(a[a[:,0]==i,1])))\n",
    "                # print(\"Valores únicos\", np.unique(a[a[:,0]==i,1]))\n",
    "                # print(\"Longitud de b[i-1]\", len(b[i-1]))\n",
    "                # print(\"+++++++++++++++++++++++++++++++++\")  \n",
    "                b[i-1] = np.unique(a[a[:,0]==i,1])\n",
    "                # b[i-1] = list(np.unique(a[a[:,0]==i,1]))\n",
    "                # print(\"valores únicos de a (stims):\", np.unique(a[a[:,0]==i,1]))\n",
    "                # print(\"a[:,0]:\", a[:,0])\n",
    "                # print(len(a[:,0]))\n",
    "                # print(\"b[]:\", b[i-1])            \n",
    "        # b = b[:,0]\n",
    "        b = b[:,1]\n",
    "        \n",
    "        for i in range(0,6):\n",
    "            if (b[i]==2):\n",
    "                r = i+1\n",
    "\n",
    "        for i in range(6,12):\n",
    "            if (b[i]==2):\n",
    "                c = i+1\n",
    "    \n",
    "        # print(\"Resultado final de b[]:\", b)\n",
    "        classlabels = np.append( classlabels, b )\n",
    "        assert (r!=0 and c!=0), 'Error %d,%d' % (r,c) \n",
    "        hlbls.append( (r,c) )\n",
    "    # print(\"hlbls:\", len(hlbls))\n",
    "    #print(\"len(classlabels):\", len(classlabels))\n",
    "    # print(\"classlabels:\", classlabels)\n",
    "\n",
    "    def SpellMeLetter(row, col):\n",
    "        spellermatrix = [ ['A','B','C','D','E','F'],\n",
    "                        [ 'G','H','I','J','K','L'],\n",
    "                    [ 'M','N','O','P','Q','R'],\n",
    "                    [ 'S','T','U','V','W','X'],\n",
    "                    [ 'Y','Z','1','2','3','4'],\n",
    "                    [ '5','6','7','8','9','_'] ]\n",
    "\n",
    "        return spellermatrix[row-1][col-1-6]\n",
    "\n",
    "    # print(\"Esta es la frase de 7 palabras de 5 letras que la persona tiene que producir.\") \n",
    "    for i in range(0,redondeo_hlbls):\n",
    "        print(SpellMeLetter(hlbls[i][0],hlbls[i][1]),end='')    \n",
    "    print()\n",
    "\n",
    "    # Luego necesito calcular los 420 averaging (de repetitions)\n",
    "    # Finalmente aprendo con 180 y me fijo si predigo los 240\n",
    "    # De los 240 adivino 20 letras (de a pares) y con eso calculo la performance\n",
    "\n",
    "    def getaverageepoch(singleepoch):\n",
    "        # Build the epochs based on each stimulation (1-12), and put all the epochs togheter.\n",
    "        # Construye las épocas/eventos en función de cada estimulación (1-12) y junte todas las épocas/eventos.\n",
    "        \n",
    "        for trial in range(0,redondeo_hlbls):\n",
    "            epochstrial = singleepoch[0+repetitions*trial:repetitions*trial+repetitions]\n",
    "            print(\"Cantidad de letras seleccionadas:\", redondeo_hlbls)\n",
    "            print(\"Posición de la letra:\", trial)\n",
    "            print(\"De dónde [:]:\", repetitions*trial)\n",
    "            print(\"A dónde [:]:\", repetitions*trial+repetitions)\n",
    "            '''\n",
    "            print(\"+++++++++++++++++++++++++++++++++\")  \n",
    "            print(\"epochstrial:\", epochstrial)\n",
    "            print(\"type(epochstrial):\", (type(epochstrial)))\n",
    "            print(\"type(epochstrial['Row1']):\", (type(epochstrial['Row1'])))\n",
    "            print(\"epochstrial.get_data())[0,8,0]:\", (epochstrial.get_data())[0,8,0])\n",
    "            print(\"epochstrial.get_data())[0,9,0]:\", (epochstrial.get_data())[0,9,0])\n",
    "                        # print(\"epochr1.shape:\", epochr1.data().shape)\n",
    "            print(\"epochstrial.get_data():\", epochstrial.get_data())\n",
    "            print(\"epochstrial.get_data().shape:\", epochstrial.get_data().shape)\n",
    "            print(\"epochstrial.get_data().shape)[0]:\", (epochstrial.get_data().shape)[0])\n",
    "            print(\"epochstrial.get_data().shape)[1]:\", (epochstrial.get_data().shape)[1])\n",
    "            print(\"epochstrial.get_data().shape)[2]:\", (epochstrial.get_data().shape)[2])\n",
    "            print(\"epochstrial.get_data())[1]:\", (epochstrial.get_data())[1])\n",
    "            print(\"epochstrial.get_data())[2]:\", (epochstrial.get_data())[2])\n",
    "            #print(\"epochstrial[:,0].get_data():\", (epochstrial[:,0].get_data()))\n",
    "            #print(f'Eventos coincidentes encontrados (con tmin:0 & tmax:0.8), {event_times[:,0].size}', file=file_temp) # También se puede obtener con {len(event_times)}\n",
    "            print(\"epochstrial.average().data.shape]:\", [epochstrial.average().data.shape])\n",
    "            #print(\"epochstrial['Row1']:\", epochstrial['Row1'])\n",
    "            print(\"(epochstrial['Row1'].data):\", epochstrial['Row1'].get_data())\n",
    "            # print(\"epochs_data\", epochs_data)\n",
    "\n",
    "            # if epochstrial['Col2'] not in epochstrial:\n",
    "            #     print(\"OJO\")\n",
    "            #    print(\"OJO\")\n",
    "            #     print(\"OJO\")\n",
    "            #    print(\"OJO\")\n",
    "            #    print(\"OJO\")\n",
    "            #    print(\"No encontró epochstrial['Row1']\")\n",
    "\n",
    "            # print(\"len(epochstrial['Row1']):\", len(epochstrial['Row1']))\n",
    "            # print(\"epochr1.shape:\", epochr1.data().shape)\n",
    "            # print(\"epochr1:\", epochr1.get_data())\n",
    "            # print(\"epochr1.get_data.shape:\", epochr1.get_data().shape)\n",
    "            # print(\"epochr1.average.data.shape:\", [epochr1.average().data.shape])\n",
    "            # print(\"epochstrial['Row1']:\", epochstrial['Row1'])\n",
    "            # print(\"epochs_data\", epochs_data)\n",
    "            \n",
    "            '''           \n",
    "            epochr1 = epochstrial['Row1'] \n",
    "            epochr2 = epochstrial['Row2'] \n",
    "            epochr3 = epochstrial['Row3']\n",
    "            epochr4 = epochstrial['Row4']\n",
    "            epochr5 = epochstrial['Row5']\n",
    "            epochr6 = epochstrial['Row6']\n",
    "            \n",
    "            epochc1 = epochstrial['Col1']\n",
    "            epochc2 = epochstrial['Col2']\n",
    "            epochc3 = epochstrial['Col3']\n",
    "            epochc4 = epochstrial['Col4']\n",
    "            epochc5 = epochstrial['Col5']\n",
    "            epochc6 = epochstrial['Col6']\n",
    "            \n",
    "            if (trial==0):\n",
    "                epochs_data = np.array([epochr1.average().data])\n",
    "                #print(\"epochs_data.shape:\", epochs_data.shape)\n",
    "            else:\n",
    "                epochs_data = np.concatenate((epochs_data, [epochr1.average().data]), axis=0)\n",
    "                #print(\"epochr1.average().data.shape:\", epochr1.average().data.shape)\n",
    "            epochs_data = np.concatenate((epochs_data, [epochr2.average().data]), axis=0)\n",
    "            epochs_data = np.concatenate((epochs_data, [epochr3.average().data]), axis=0)\n",
    "            epochs_data = np.concatenate((epochs_data, [epochr4.average().data]), axis=0)\n",
    "            epochs_data = np.concatenate((epochs_data, [epochr5.average().data]), axis=0)\n",
    "            epochs_data = np.concatenate((epochs_data, [epochr6.average().data]), axis=0)\n",
    "\n",
    "            epochs_data = np.concatenate((epochs_data, [epochc1.average().data]), axis=0)\n",
    "            epochs_data = np.concatenate((epochs_data, [epochc2.average().data]), axis=0)\n",
    "            epochs_data = np.concatenate((epochs_data, [epochc3.average().data]), axis=0)\n",
    "            epochs_data = np.concatenate((epochs_data, [epochc4.average().data]), axis=0)\n",
    "            epochs_data = np.concatenate((epochs_data, [epochc5.average().data]), axis=0)\n",
    "            epochs_data = np.concatenate((epochs_data, [epochc6.average().data]), axis=0)\n",
    "\n",
    "            # print(f'epochs_data: ', epochs_data)\n",
    "\n",
    "        # There are 420 epochs, which correspond to 35 letters, in groups of 12.\n",
    "        events=np.array([np.arange(len(classlabels)),np.zeros(len(classlabels)), classlabels])\n",
    "        events = events.T\n",
    "        events = events.astype(int)\n",
    "                        \n",
    "        tmin = 0\n",
    "        tmax = 0.8\n",
    "        event_id = { 'first':1, 'second':2 }\n",
    "        info = mne.create_info(ch_names, 250, ch_types=ch_types)\n",
    "        custom_epochs = mne.EpochsArray(epochs_data, info, events, tmin, event_id) \n",
    "\n",
    "        return custom_epochs\n",
    "\n",
    "    # avepochs contains all the 420 averaged epochs, 7 letters of 5, with 12 each.\n",
    "    custom_epochs = getaverageepoch(stimepochs)          \n",
    "\n",
    "    # Performs the final classification, the one that allows to produce the spelled letters.\n",
    "    print('Performance Classification of Averaged Epochs')\n",
    "    clf = LogisticRegression(solver='lbfgs')\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # create a linear model with LogisticRegression\n",
    "    model = LinearModel(clf)\n",
    "\n",
    "    # =============================================\n",
    "    # Acá redimensiono el dataset para que training y test queden \n",
    "    # en función de la cantidad de eventos reales encontrados.\n",
    "    # no 420 exactos.\n",
    "    eventos_encontrados = len(custom_epochs)  \n",
    "    long_training = int(abs(len(custom_epochs))*(0.43))\n",
    "    long_test = ((len(custom_epochs))-long_training)\n",
    "    #redondeo_hlbls\n",
    "    redondeo_hlbls_40 = int(abs(redondeo_hlbls*(0.4)))\n",
    "    #print(\"redondeo_hlbls_40:\", redondeo_hlbls_40)\n",
    "    # =============================================\n",
    "\n",
    "    # print(\"len(eventos_encontrados):\", len(custom_epochs))\n",
    "    # print(\"long_training:\", long_training)\n",
    "    # print(\"long_test:\", long_test)\n",
    "    # print(\"redondeo_hlbls:\", redondeo_hlbls)\n",
    "    # print(\"redondeo_hlbls_40:\", redondeo_hlbls_40)\n",
    "\n",
    "    # training = range(0,180)\n",
    "    # test = range(180,420)\n",
    "\n",
    "    training = range(0,long_training)\n",
    "    test = range(long_training,eventos_encontrados)\n",
    "\n",
    "    #print(\"training:\", training)\n",
    "    #print(\"test:\", test)\n",
    "\n",
    "    eeg_data = custom_epochs.get_data()\n",
    "\n",
    "    #print(\"Tipo (eeg_data) : \", type(eeg_data))\n",
    "    #print(\"len(eeg_data):\", len(eeg_data))\n",
    "    # print(\"shape(eeg_data):\", eeg_data.shape)\n",
    "    #print(\"eeg_data:\", eeg_data)\n",
    "    #np.savetxt(f'./a_results/eeg_data.csv', eeg_data, delimiter=',',fmt='%s')\n",
    "    # np.savetxt(f'./a_results/events2.csv', events, delimiter='\\t',fmt='%s')\n",
    "\n",
    "    eeg_data = eeg_data.reshape(eventos_encontrados, -1)\n",
    "\n",
    "    # print(\"re-shape(eeg_data):\", eeg_data.shape)\n",
    "\n",
    "    eeg_data = eeg_data[:,0:201]\n",
    "\n",
    "    #eeg_data[classlabels==2] = np.zeros((eeg_data.shape[1],))\n",
    "    #eeg_data[classlabels==1] = np.ones((eeg_data.shape[1],))\n",
    "\n",
    "    #X = scaler.fit_transform(eeg_data)\n",
    "\n",
    "    X = eeg_data\n",
    "\n",
    "    cf = clf.fit(X[training], classlabels[training])\n",
    "\n",
    "    classpreds = np.empty ((eventos_encontrados,2))\n",
    "\n",
    "    classpreds[test,:] = clf.predict_proba(X[test])\n",
    "\n",
    "    hpreds = []\n",
    "\n",
    "    for trial in range(redondeo_hlbls_40,redondeo_hlbls):\n",
    "    #for trial in range(15,35):\n",
    "        #print('Row')\n",
    "        for i in range(0,6):\n",
    "            preds = classpreds[trial*12+i]\n",
    "            #print ( preds[1] )\n",
    "            labels = classlabels[trial*12+i]\n",
    "\n",
    "        #print (  np.argmin( classpreds[trial*12+0:trial*12+6]))\n",
    "        r = np.argmax( classpreds[trial*12+0:trial*12+6,1])+1\n",
    "        \n",
    "        #print('Col')\n",
    "        for i in range(6,12):\n",
    "            preds = classpreds[trial*12+i]\n",
    "            #print ( preds[1] )\n",
    "            labels = classlabels[trial*12+i]\n",
    "\n",
    "        #print (  np.argmin( classpreds[trial*12+6:trial*12+12]))\n",
    "        c = np.argmax( classpreds[trial*12+6:trial*12+12,1])+1\n",
    "\n",
    "        hpreds.append( (r,c) )\n",
    "\n",
    "    # print(\"lo esperado:\")\n",
    "    for i in range(redondeo_hlbls_40,redondeo_hlbls):\n",
    "    #for i in range(15,35):\n",
    "        print(SpellMeLetter(hlbls[i][0],hlbls[i][1]),end='')\n",
    "    print()\n",
    "\n",
    "    # print(\"lo predecido\")\n",
    "    for i in range(redondeo_hlbls_40,redondeo_hlbls):\n",
    "    #for i in range(15,35):\n",
    "        print(SpellMeLetter(hpreds[i-15][0],hpreds[i-15][1]),end='')\n",
    "    print()\n",
    "\n",
    "    '''\n",
    "    # %%\n",
    "    for i in range(0,12):\n",
    "        plt.figure(figsize=(9, 3))\n",
    "        plt.plot(eeg_data[i])\n",
    "        plt.show()\n",
    "    # %%\n",
    "    '''\n",
    "\n",
    "    # Classification report\n",
    "    target_names = ['nohit', 'hit']\n",
    "    report = classification_report(classlabels[test], clf.predict(X[test]), target_names=target_names)\n",
    "    # print(report)\n",
    "    # print(f'report: ', report)\n",
    "    cm = confusion_matrix(classlabels[test], clf.predict(X[test]) )\n",
    "    # print (cm)\n",
    "    cm_normalized = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis]\n",
    "    acc=(cm[0,0]+cm[1,1])*1.0/(np.sum(cm))\n",
    "    # print(\"cm:\", cm)\n",
    "    print(\"-----------------------------------------\")  \n",
    "    # print(f'Accuracy P3S00{ii+1}: {acc}') # COLUMNA0.\n",
    "    print(f'P{ii+1}, {acc}, {repetitions}, {porcentaje}, ', file=file_temp)\n",
    "    print('Accuracy:',acc)\n",
    "    print(\"-----------------------------------------\")  \n",
    "\n",
    "file_temp.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "f8696d3d898bc62b90f4cd7d878fc87a051ec77bbff0b42338ab50969b9d3714"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
