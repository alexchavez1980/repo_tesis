{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4040 events found\n",
      "Event IDs: [ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "Not setting metadata\n",
      "4040 matching events found\n",
      "No baseline correction applied\n",
      "Using data from preloaded Raw for 4040 events and 201 original time points ...\n",
      "0 bad epochs dropped\n",
      "4004 events found\n",
      "Event IDs: [1 2]\n",
      "Not setting metadata\n",
      "3333 matching events found\n",
      "No baseline correction applied\n",
      "Using data from preloaded Raw for 3333 events and 201 original time points ...\n",
      "0 bad epochs dropped\n",
      "4004 events found\n",
      "Event IDs: [1 2]\n",
      "Not setting metadata\n",
      "671 matching events found\n",
      "No baseline correction applied\n",
      "Using data from preloaded Raw for 671 events and 201 original time points ...\n",
      "0 bad epochs dropped\n",
      "4004 events found\n",
      "Event IDs: [1 2]\n",
      "Not setting metadata\n",
      "4004 matching events found\n",
      "No baseline correction applied\n",
      "Using data from preloaded Raw for 4004 events and 201 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       nohit       0.89      0.98      0.93      1000\n",
      "         hit       0.81      0.41      0.54       204\n",
      "\n",
      "    accuracy                           0.88      1204\n",
      "   macro avg       0.85      0.69      0.74      1204\n",
      "weighted avg       0.88      0.88      0.87      1204\n",
      "\n",
      "[[980  20]\n",
      " [121  83]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (2,) into shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11608/359266049.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         \u001b[0mb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (2,) into shape (1,)"
     ]
    }
   ],
   "source": [
    "# In[1]:\n",
    "import mne\n",
    "mne.set_log_level('WARNING')\n",
    "\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# First load the template.  This is the signal that will be used to DRUG the basal EEG stream.\n",
    "mat = scipy.io.loadmat('./dataset/ERPTemplate.mat')\n",
    "\n",
    "routput = mat['routput']\n",
    "\n",
    "# In this ERPTemplate, there are two different template signals that are good.\n",
    "erptemplate1 = routput[0][7][0][1][0][0][0][7] \n",
    "erptemplate2 = routput[0][7][0][1][0][0][0][0] \n",
    "\n",
    "# The original ERPTemplate dataset has a sampling frequency of 256 so I need to perform a small downsampling to 250 Hz\n",
    "erptemplate1 = np.delete( erptemplate1, range(0,256,43),0)\n",
    "erptemplate2 = np.delete( erptemplate2, range(0,256,43),0)\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------\n",
    "# Modificaciones para la arga de todos los archivos y ejecución de DrigSignal con \n",
    "# el vector aleatorio de templates ERP alterados en amplitud.\n",
    "#-----------------------------------------------------------------------\n",
    "v_min = erptemplate1.min()*3\n",
    "v_max = erptemplate1.max()*3\n",
    "array_DrugAmpERPtemplate = np.empty(5,dtype=object)\n",
    "for i in range(5):\n",
    "    v_aleatorio = np.random.uniform(v_min, v_max, (1, 8)) \n",
    "    #print(f'v_aleatorio({i}): ',v_aleatorio)\n",
    "    # v_aleatorio = [-5,1,5,0,5,0,5,0] # Vector fijo para testing\n",
    "    DrugAmpERPtemplate = np.empty_like(erptemplate1) # Inicializo un array igual que erptemplate1\n",
    "    for j in range(erptemplate1.shape[0]):\n",
    "        DrugAmpERPtemplate[j, :] = erptemplate1[j, :] + v_aleatorio\n",
    "    array_DrugAmpERPtemplate[i] = DrugAmpERPtemplate\n",
    "    #print(f'array_DrugAmpERPtemplate[{i}].min()', array_DrugAmpERPtemplate[i].min())\n",
    "    #print(f'array_DrugAmpERPtemplate[{i}].max()', array_DrugAmpERPtemplate[i].max())\n",
    "    #print('----------------------------------------------------')\n",
    "\n",
    "# DrugSignal Alex\n",
    "\n",
    "# np.save('./dataset/ERPTemplate.mat/array_DrugAmpERPtemplate.npy', array_DrugAmpERPtemplate)\n",
    "# array_DrugAmpERPtemplate = np.load('./dataset/array_DrugAmpERPtemplate.npy', allow_pickle=True)\n",
    "len_array_DrugAmpERPtemplate = np.arange(0,len(array_DrugAmpERPtemplate))\n",
    "# print(\"Tamaño del vector array_DrugAmpERPtemplate\", len_array_DrugAmpERPtemplate)\n",
    "\n",
    "# Randomize amplitude and jitter.\n",
    "# Find the right locations where this should be inserted in the stream.\n",
    "# Insert the signal mantaining the continiuity of the EEG.\n",
    "def DrugSignal(signal, t_flash):\n",
    "    '''\n",
    "    Randomize amplitude and jitter\n",
    "    Find the right locations where this should be inserted in the stream\n",
    "    Insert the template mantaining the continuity and physiological meaning of the EEG\n",
    "    '''\n",
    "    for i in range(0,4200):\n",
    "        if (t_flash[i,3]==2):\n",
    "            random_DrugAmpERPtemplate = random.choice(len_array_DrugAmpERPtemplate)\n",
    "            #print(\"Valor aleatorio seleccionado:\", random_DrugAmpERPtemplate)\n",
    "            signal[t_flash[i,0]-1:t_flash[i,0]+250-1,:] += (array_DrugAmpERPtemplate[random_DrugAmpERPtemplate])\n",
    "            #print(\"array_DrugAmpERPtemplate:\", array_DrugAmpERPtemplate[random_DrugAmpERPtemplate])\n",
    "    return signal\n",
    "\n",
    "#-----------------------------------------------------------------------\n",
    "# Empieza con # Randomize amplitude and jitter.\n",
    "# Finaliza con return signal\n",
    "#-----------------------------------------------------------------------\n",
    "    \n",
    "# Now load the basal EEG stream\n",
    "mat = scipy.io.loadmat('./dataset/itba/P300S01.mat')\n",
    "# mat = scipy.io.loadmat('./dataset/p300-subject-25.mat')\n",
    "#mat = scipy.io.loadmat('./dataset/p300-subject-26.mat')\n",
    "#mat = scipy.io.loadmat('/Users/rramele/./GoogleDrive/Data/P300/p300-subject-21.mat')\n",
    "#mat = scipy.io.loadmat('/Users/rramele/./GoogleDrive/Data/P300/p300-subject-06.mat')\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "# coding: latin-1\n",
    "# Data point zero for the eight channels.  Should be in V.\n",
    "signal = mat['data'][0][0][0] \n",
    "#* pow(10,6)\n",
    "\n",
    "# Trials\n",
    "t_trials = mat['data'][0][0][3]\n",
    "\n",
    "# Flash matrix\n",
    "t_flash = mat['data'][0][0][4]\n",
    "\n",
    "signal = DrugSignal(signal, t_flash)\n",
    "\n",
    "t_stim = mat['data'][0][0][2]\n",
    "t_type = mat['data'][0][0][1]\n",
    "\n",
    "\n",
    "ch_names=[ 'Fz'  ,  'Cz',    'P3' ,   'Pz'  ,  'P4'  ,  'PO7'   , 'PO8'   , 'Oz']\n",
    "ch_types= ['eeg'] * signal.shape[1]\n",
    "\n",
    "ch_names_events = ch_names + ['t_stim']+ ['t_type']\n",
    "ch_types_events = ch_types + ['misc'] + ['misc']\n",
    "\n",
    "#info = mne.create_info(ch_names, 250, ch_types=ch_types)\n",
    "#eeg_mne = mne.io.array.RawArray(signal.T, info)\n",
    "\n",
    "signal_events = np.concatenate([signal, t_stim, t_type],1)\n",
    "info_events = mne.create_info(ch_names_events,250, ch_types_events)\n",
    "eeg = mne.io.RawArray(signal_events.T, info_events)\n",
    "\n",
    "# Do some basic signal processing (1-20 band pass filter)\n",
    "#fig=eeg.plot_psd()\n",
    "\n",
    "eeg.filter(1,20)\n",
    "\n",
    "#fig=eeg.plot_psd()\n",
    "\n",
    "event_times = mne.find_events(eeg, stim_channel='t_type')    \n",
    "\n",
    "\n",
    "\n",
    "# eeg.plot(scalings='auto',n_channels=8,events=event_times,block=True)   # scalings=10e-05\n",
    "\n",
    "# In[1]\n",
    "if (np.unique(t_flash[:,0]).shape[0] != 4200):\n",
    "    u,c = np.unique( t_flash[:,0], return_counts=True)\n",
    "    dup = u[c>1]\n",
    "    for i in range(dup.shape[0]):\n",
    "        idx = np.where( t_flash[:,0] == dup[i] )[0][0]\n",
    "        t_flash[idx,0]  -= 1\n",
    "        t_flash[idx,1]  = 1\n",
    "        t_type[t_flash[idx,0]] = t_flash[idx,3]\n",
    "        t_stim[t_flash[idx,0]] = t_flash[idx,2]\n",
    "\n",
    "# In[1]:\n",
    "np.unique(t_flash[:,0]).shape\n",
    "assert  np.unique(t_flash[:,0]).shape[0] == 4200, 'Problem with experiment structure.  There aren''t enough events.'\n",
    "\n",
    "\n",
    "# %%\n",
    "def getstims(eeg_mne, eeg_events):\n",
    "    '''\n",
    "    Get the stimulations.  These are the FLASHINGS of rows and columns.\n",
    "    '''\n",
    "    tmin = 0\n",
    "    tmax = 0.8\n",
    "    reject = None\n",
    "    event_times = mne.find_events(eeg_events, stim_channel='t_stim',shortest_event=0, verbose=True, min_duration=0.000001, consecutive=True)\n",
    "    event_id = {'Row1':1,'Row2':2,'Row3':3,'Row4':4,'Row5':5,'Row6':6,'Col1':7,'Col2':8,'Col3':9,'Col4':10,'Col5':11,'Col6':12}\n",
    "\n",
    "\n",
    "    epochs = mne.Epochs(eeg_mne, event_times, event_id, tmin, tmax, proj=False,\n",
    "                    baseline=None, reject=reject, preload=True,\n",
    "                    verbose=True, reject_by_annotation=None)\n",
    "\n",
    "\n",
    "    stims = event_times[:,-1]\n",
    "\n",
    "    return [epochs,stims]\n",
    "\n",
    "stimepochs, stims = getstims(eeg, eeg)\n",
    "\n",
    "\n",
    "def getlabels(eeg_mne, eeg_events, event_id):\n",
    "    '''\n",
    "    Get the hit/no hits labels.  These are the FLASHINGS of rows and columns but selected if they are the ones that will\n",
    "    trigger the P300 response or not.\n",
    "    '''\n",
    "    #event_id = { 'first':1, 'second':2 }\n",
    "    #baseline = (0.0, 0.2)\n",
    "    #reject = {'eeg': 70 * pow(10,6)}\n",
    "    tmin = 0\n",
    "    tmax = 0.8\n",
    "    reject = None\n",
    "    event_times = mne.find_events(eeg_events, stim_channel='t_type', shortest_event=0, verbose=True, min_duration=0.000001, consecutive=True)\n",
    "    epochs = mne.Epochs(eeg_mne, event_times, event_id, tmin, tmax, proj=False,\n",
    "                    baseline=None, reject=reject, preload=True,\n",
    "                    verbose=True, reject_by_annotation=None)\n",
    "    labels = epochs.events[:, -1]\n",
    "    return [epochs, labels]\n",
    "\n",
    "epochs, labels = getlabels(eeg, eeg, {'first':1})\n",
    "\n",
    "epocked = epochs.average()\n",
    "# epocked.plot(window_title='NoHit Averaged Signals')\n",
    "\n",
    "\n",
    "epochs, labels = getlabels(eeg, eeg, {'second':2})\n",
    "\n",
    "epocked = epochs.average()\n",
    "# epocked.plot(window_title='Hit Averaged Signals')\n",
    "\n",
    "epochs, labels = getlabels(eeg, eeg, { 'first':1, 'second':2})\n",
    "\n",
    "\n",
    "# Downsample the original FS=250 Hz signal to >>> 20 Hz\n",
    "#epochs.resample(20, npad=\"auto\")\n",
    "#stimepochs.resample(20, npad=\"auto\")\n",
    "repetitions=120\n",
    "\n",
    "# %%\n",
    "# This is Single Flashing Classification attempt.\n",
    "from sklearn.preprocessing import  StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# import a linear classifier from mne.decoding\n",
    "from mne.decoding import LinearModel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# create a linear model with LogisticRegression\n",
    "model = LinearModel(clf)\n",
    "\n",
    "# Get the epoched data (get only the data columns)\n",
    "eeg_data = epochs.get_data().reshape(len(labels), -1)\n",
    "eeg_data = eeg_data[:,0:epochs.get_data().shape[2]*1]\n",
    "#eeg_data[labels==2] = erptemplate1[:201,0]\n",
    "#eeg_data[labels==1] = erptemplate1[:201,0]\n",
    "\n",
    "#eeg_data[labels==2] = np.zeros((eeg_data.shape[1],))\n",
    "#eeg_data[labels==1] = np.ones((eeg_data.shape[1],))\n",
    "\n",
    "#labels = np.random.permutation(labels)\n",
    "\n",
    "# fit the classifier on MEG data\n",
    "X = scaler.fit_transform(eeg_data)\n",
    "\n",
    "model.fit(X[0:2800], labels[0:2800])\n",
    "\n",
    "preds = model.predict(X[2800:])\n",
    "\n",
    "# Classification report\n",
    "target_names = ['nohit', 'hit']\n",
    "\n",
    "report = classification_report(labels[2800:], preds, target_names=target_names)\n",
    "print(report)\n",
    "\n",
    "cm = confusion_matrix(labels[2800:], preds)\n",
    "print (cm)\n",
    "cm_normalized = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis]\n",
    "acc=(cm[0,0]+cm[1,1])*1.0/(np.sum(cm))\n",
    "\n",
    "# %%\n",
    "#import matplotlib.pyplot as plt\n",
    "#for i in range(200,220):\n",
    "#    plt.figure(figsize=(9, 3))\n",
    "#    plt.plot(eeg_data[labels==1][i])\n",
    "#    plt.show()\n",
    "\n",
    "\n",
    "# In[1]:   Average classification x trial (unbalanced)\n",
    "# Este dataset es un dataset de calibración. El registro de EEG corresponde a un experimento del Speller\n",
    "# de 35 letras (7 palabras de 5 letras).   Cada una de las letras consiste en 10 repeticiones de la intensificación \n",
    "# de los 12 estímulos distintos, siendo cada estímulo el FLASHING de una de las 6 filas o 6 columnas.\n",
    "# Cada vez que se repite, se hace una permutación de los 12.\n",
    "# En cada una de esos 12 estímulos, dos, uno correspondiente a una fila y a una columna, corresponden \n",
    "# a la letra que la persona está prestando atención y la idea es que el sistema descubra que letra es.\n",
    "\n",
    "# Primero tengo que agarrar la lista de labels y asignar a los 420 (35x12)\n",
    "# el label que le corresponde a cada uno.  Es decir de los primeros 12, 10\n",
    "# son no hits y 2 hits.\n",
    "\n",
    "# hlbls tiene pares (r,c) que representan la fila y la columna donde está la letra\n",
    "# que la persona tiene que elegir. \n",
    "hlbls = []\n",
    "hpreds = []\n",
    "classlabels=np.asarray([])\n",
    "for trial in range(0,35):\n",
    "    a=np.zeros((12*10,2))\n",
    "    a[:,0] = stims[0+120*trial:0+120*trial+120]\n",
    "    a[:,1] = labels[0+120*trial:0+120*trial+120]\n",
    "\n",
    "    b=np.zeros((12,1))\n",
    "\n",
    "    for i in range(1,13):\n",
    "        b[i-1] = np.unique(a[a[:,0]==i,1])\n",
    "\n",
    "    for i in range(0,6):\n",
    "        if (b[i]==2):\n",
    "            r = i+1\n",
    "\n",
    "    for i in range(6,12):\n",
    "        if (b[i]==2):\n",
    "            c = i+1\n",
    "\n",
    "    classlabels = np.append( classlabels, b )\n",
    "\n",
    "    assert (r!=0 and c!=0), 'Error %d,%d' % (r,c) \n",
    "    hlbls.append( (r,c) )\n",
    "\n",
    "# In[1]:  \n",
    "def SpellMeLetter(row, col):\n",
    "    spellermatrix = [ ['A','B','C','D','E','F'],\n",
    "                    [ 'G','H','I','J','K','L'],\n",
    "                [ 'M','N','O','P','Q','R'],\n",
    "                [ 'S','T','U','V','W','X'],\n",
    "                [ 'Y','Z','1','2','3','4'],\n",
    "                [ '5','6','7','8','9','_'] ]\n",
    "\n",
    "    return spellermatrix[row-1][col-1-6]\n",
    "\n",
    "# Esta es la frase de 7 palabras de 5 letras que la persona tiene que producir.\n",
    "for i in range(0,35):\n",
    "    print(SpellMeLetter(hlbls[i][0],hlbls[i][1]),end='')\n",
    "\n",
    "print()\n",
    "# In[1]: \n",
    "# Luego necesito calcular los 420 averaging (de repetitions)\n",
    "# Finalmente aprendo con 180 y me fijo si predigo los 240\n",
    "# De los 240 adivino 20 letras (de a pares) y con eso calculo la performance\n",
    "\n",
    "def getaverageepoch(singleepoch):\n",
    "    '''\n",
    "    Build the epochs based on each stimulation (1-12), and put all the epochs togheter.\n",
    "    '''\n",
    "    for trial in range(0,35):\n",
    "        epochstrial = singleepoch[0+repetitions*trial:repetitions*trial+repetitions]\n",
    "\n",
    "        epochr1 = epochstrial['Row1']\n",
    "        epochr2 = epochstrial['Row2']\n",
    "        epochr3 = epochstrial['Row3']\n",
    "        epochr4 = epochstrial['Row4']\n",
    "        epochr5 = epochstrial['Row5']\n",
    "        epochr6 = epochstrial['Row6']\n",
    "\n",
    "        epochc1 = epochstrial['Col1']\n",
    "        epochc2 = epochstrial['Col2']\n",
    "        epochc3 = epochstrial['Col3']\n",
    "        epochc4 = epochstrial['Col4']\n",
    "        epochc5 = epochstrial['Col5']\n",
    "        epochc6 = epochstrial['Col6']\n",
    "\n",
    "        if (trial==0):\n",
    "            epochs_data = np.array([epochr1.average().data])\n",
    "        else:\n",
    "            epochs_data = np.concatenate((epochs_data, [epochr1.average().data]), axis=0)\n",
    "\n",
    "        epochs_data = np.concatenate((epochs_data, [epochr2.average().data]), axis=0)\n",
    "        epochs_data = np.concatenate((epochs_data, [epochr3.average().data]), axis=0)\n",
    "        epochs_data = np.concatenate((epochs_data, [epochr4.average().data]), axis=0)\n",
    "        epochs_data = np.concatenate((epochs_data, [epochr5.average().data]), axis=0)\n",
    "        epochs_data = np.concatenate((epochs_data, [epochr6.average().data]), axis=0)\n",
    "\n",
    "        epochs_data = np.concatenate((epochs_data, [epochc1.average().data]), axis=0)\n",
    "        epochs_data = np.concatenate((epochs_data, [epochc2.average().data]), axis=0)\n",
    "        epochs_data = np.concatenate((epochs_data, [epochc3.average().data]), axis=0)\n",
    "        epochs_data = np.concatenate((epochs_data, [epochc4.average().data]), axis=0)\n",
    "        epochs_data = np.concatenate((epochs_data, [epochc5.average().data]), axis=0)\n",
    "        epochs_data = np.concatenate((epochs_data, [epochc6.average().data]), axis=0)\n",
    "\n",
    "    # There are 420 epochs, which correspond to 35 letters, in groups of 12.\n",
    "    events=np.array([np.arange(420),np.zeros(420), classlabels])\n",
    "    events = events.T\n",
    "    events = events.astype(int)\n",
    "\n",
    "    tmin = 0\n",
    "    tmax = 0.8\n",
    "    event_id = { 'first':1, 'second':2 }\n",
    "    info = mne.create_info(ch_names, 250, ch_types=ch_types)\n",
    "    custom_epochs = mne.EpochsArray(epochs_data, info, events, tmin, event_id) \n",
    "\n",
    "    return custom_epochs\n",
    "\n",
    "# avepochs contains all the 420 averaged epochs, 7 letters of 5, with 12 each.\n",
    "custom_epochs = getaverageepoch(stimepochs)\n",
    "\n",
    "\n",
    "# In[1]: \n",
    "# Performs the final classification, the one that allows to produce the spelled letters.\n",
    "print('Performance Classification of Averaged Epochs')\n",
    "clf = LogisticRegression(solver='lbfgs')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# create a linear model with LogisticRegression\n",
    "model = LinearModel(clf)\n",
    "\n",
    "training = range(0,180)\n",
    "test = range(180,420)\n",
    "\n",
    "eeg_data = custom_epochs.get_data()\n",
    "\n",
    "eeg_data = eeg_data.reshape(420, -1)\n",
    "eeg_data = eeg_data[:,0:201]\n",
    "\n",
    "#eeg_data[classlabels==2] = np.zeros((eeg_data.shape[1],))\n",
    "#eeg_data[classlabels==1] = np.ones((eeg_data.shape[1],))\n",
    "\n",
    "#X = scaler.fit_transform(eeg_data)\n",
    "\n",
    "X = eeg_data\n",
    "\n",
    "cf = clf.fit(X[training], classlabels[training])\n",
    "\n",
    "classpreds = np.empty ((420,2))\n",
    "\n",
    "classpreds[test,:] = clf.predict_proba(X[test])\n",
    "\n",
    "hpreds = []\n",
    "\n",
    "for trial in range(15,35):\n",
    "    #print('Row')\n",
    "    for i in range(0,6):\n",
    "        preds = classpreds[trial*12+i]\n",
    "        #print ( preds[1] )\n",
    "        labels = classlabels[trial*12+i]\n",
    "\n",
    "    #print (  np.argmin( classpreds[trial*12+0:trial*12+6]))\n",
    "    r = np.argmax( classpreds[trial*12+0:trial*12+6,1])+1\n",
    "    \n",
    "\n",
    "    #print('Col')\n",
    "    for i in range(6,12):\n",
    "        preds = classpreds[trial*12+i]\n",
    "        #print ( preds[1] )\n",
    "        labels = classlabels[trial*12+i]\n",
    "\n",
    "    #print (  np.argmin( classpreds[trial*12+6:trial*12+12]))\n",
    "    c = np.argmax( classpreds[trial*12+6:trial*12+12,1])+1\n",
    "\n",
    "    hpreds.append( (r,c) )\n",
    "\n",
    "# In[1]: \n",
    "for i in range(15,35):\n",
    "    print(SpellMeLetter(hlbls[i][0],hlbls[i][1]),end='')\n",
    "\n",
    "print()\n",
    "\n",
    "# In[1]: \n",
    "for i in range(15,35):\n",
    "    print(SpellMeLetter(hpreds[i-15][0],hpreds[i-15][1]),end='')\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "# %%\n",
    "for i in range(0,12):\n",
    "    plt.figure(figsize=(9, 3))\n",
    "    plt.plot(eeg_data[i])\n",
    "    plt.show()\n",
    "# %%\n",
    "\n",
    "# Classification report\n",
    "target_names = ['nohit', 'hit']\n",
    "\n",
    "report = classification_report(classlabels[test], clf.predict(X[test]), target_names=target_names)\n",
    "print(report)\n",
    "\n",
    "cm = confusion_matrix(classlabels[test], clf.predict(X[test]) )\n",
    "print (cm)\n",
    "cm_normalized = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis]\n",
    "acc=(cm[0,0]+cm[1,1])*1.0/(np.sum(cm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b958d2ee4113081da5b7324adcb012071bef3fd829261c203699a43a2ce6bc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
